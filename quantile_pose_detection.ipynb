{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe numpy\n",
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2uE30coO-59",
        "outputId": "40fea17c-634d-460a-8082-ae0cb4649327"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eO5y0UpSO-eV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import scipy\n",
        "import os\n",
        "import time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/mlp\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeT3XkjuQE9D",
        "outputId": "77a55041-be87-46c4-96db-54ffed72e0be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvpNxidLt_5m",
        "outputId": "0c42272e-dbd8-49b5-f1c0-b4e2f0b0cc65"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_video_reps(video_name, reps_data, save_dir='processed_data'):\n",
        "    \"\"\"\n",
        "    Save rep data for a single video to a .npz file.\n",
        "\n",
        "    Args:\n",
        "        video_name (str): Name of the video file\n",
        "        reps_data (list): List of numpy arrays containing rep data\n",
        "        save_dir (str): Directory to save the .npz files\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    save_path = os.path.join(save_dir, video_name.replace('.mp4', '.npz'))\n",
        "    save_dict = {f'rep_{i}': rep for i, rep in enumerate(reps_data)}\n",
        "    np.savez_compressed(save_path, **save_dict)\n",
        "\n",
        "def process_videos_directory(data_dir, save_dir='processed_data'):\n",
        "    \"\"\"\n",
        "    Process all videos in directory, skipping those that already have .npz files.\n",
        "\n",
        "    Args:\n",
        "        data_dir (str): Directory containing videos\n",
        "        save_dir (str): Directory to save processed data\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of processed videos and their rep data\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    all_sets_data = {}\n",
        "\n",
        "    for file in os.listdir(data_dir):\n",
        "        if file.endswith('.mp4'):\n",
        "            npz_path = os.path.join(save_dir, file.replace('.mp4', '.npz'))\n",
        "\n",
        "            if os.path.exists(npz_path):\n",
        "                print(f\"Skipping {file} - already processed\")\n",
        "                continue\n",
        "\n",
        "            print(f\"Processing {file}...\")\n",
        "            video_path = os.path.join(data_dir, file)\n",
        "            set_data = extract_rep_joint_data(video_path)\n",
        "            all_sets_data[file] = set_data\n",
        "\n",
        "            # Save the processed data\n",
        "            save_video_reps(file, set_data, save_dir)\n",
        "            print(f\"Found and saved {len(set_data)} reps for {file}\")\n",
        "\n",
        "    return all_sets_data\n",
        "\n",
        "def save_existing_reps_data(all_reps_data, save_dir='processed_data'):\n",
        "    \"\"\"\n",
        "    Save any rep data currently in memory that hasn't been saved yet.\n",
        "\n",
        "    Args:\n",
        "        all_reps_data (dict): Dictionary mapping video names to rep data\n",
        "        save_dir (str): Directory to save processed data\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for video_name, set_data in all_reps_data.items():\n",
        "        npz_path = os.path.join(save_dir, video_name.replace('.mp4', '.npz'))\n",
        "        if not os.path.exists(npz_path):\n",
        "            print(f\"Saving data for {video_name}...\")\n",
        "            save_video_reps(video_name, set_data, save_dir)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def load_all_processed_data(processed_dir='processed_data'):\n",
        "    \"\"\"\n",
        "    Load all processed rep data from .npz files in directory.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary mapping video names to a list of rep arrays.\n",
        "              Each rep array should ideally have shape (timesteps, 4).\n",
        "    \"\"\"\n",
        "    all_sets_data = {}\n",
        "\n",
        "    for file in os.listdir(processed_dir):\n",
        "        if file.endswith('.npz'):\n",
        "            video_name = file.replace('.npz', '.mp4')\n",
        "            npz_path = os.path.join(processed_dir, file)\n",
        "\n",
        "            loaded = np.load(npz_path)\n",
        "            rep_keys = [k for k in loaded.files if k.startswith('rep_')]\n",
        "            rep_keys.sort(key=lambda x: int(x.split('_')[1])) # Sort based on rep number\n",
        "\n",
        "            reps = [loaded[key] for key in rep_keys]\n",
        "\n",
        "            # Print shape of each rep\n",
        "            for i, rep in enumerate(reps):\n",
        "                print(f\"Rep {i} shape for {video_name}: {rep.shape}\")\n",
        "\n",
        "            all_sets_data[video_name] = reps\n",
        "            print(f\"Loaded {len(reps)} reps from {video_name}\")\n",
        "\n",
        "    return all_sets_data\n"
      ],
      "metadata": {
        "id": "Po5yCfnz9v_r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def prepare_rep_for_lstm_quantiles(rep_data, fps=30, num_quantiles=5):\n",
        "    \"\"\"\n",
        "    Prepares a single repetition's joint data for LSTM input by:\n",
        "    1. Computing ROM (Range of Motion)\n",
        "    2. Computing velocities\n",
        "    3. Extracting values at specific quantiles (1/5, 2/5, 3/5, 4/5, 5/5)\n",
        "\n",
        "    Args:\n",
        "        rep_data (np.ndarray): Array of shape (timesteps, 4) containing\n",
        "                              [elbow_x, elbow_y, wrist_x, wrist_y]\n",
        "        fps (int): Frames per second of the video\n",
        "        num_quantiles (int): Number of quantiles to extract (default: 5)\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Processed features of shape (num_quantiles, n_features)\n",
        "                   Features: [norm_elbow_x, norm_elbow_y, norm_wrist_x, norm_wrist_y,\n",
        "                            elbow_velocity, wrist_velocity, rom_percentage]\n",
        "    \"\"\"\n",
        "\n",
        "    normalized_coords = rep_data\n",
        "\n",
        "    # 2. Calculate ROM (Range of Motion)\n",
        "    wrist_to_elbow = np.sqrt(\n",
        "        (rep_data[:, 2] - rep_data[:, 0])**2 +\n",
        "        (rep_data[:, 3] - rep_data[:, 1])**2\n",
        "    )\n",
        "    rom = wrist_to_elbow - np.min(wrist_to_elbow)\n",
        "    rom_percentage = rom / np.max(rom)\n",
        "\n",
        "    # 3. Calculate velocities (change in position per frame)\n",
        "    dt = 1/fps\n",
        "    elbow_velocity = np.sqrt(\n",
        "        np.gradient(normalized_coords[:, 0])**2 +\n",
        "        np.gradient(normalized_coords[:, 1])**2\n",
        "    ) / dt\n",
        "    wrist_velocity = np.sqrt(\n",
        "        np.gradient(normalized_coords[:, 2])**2 +\n",
        "        np.gradient(normalized_coords[:, 3])**2\n",
        "    ) / dt\n",
        "\n",
        "    # 4. Extract values at quantiles\n",
        "    quantile_indices = np.round(np.linspace(0, len(rep_data) - 1, num_quantiles)).astype(int)\n",
        "\n",
        "    # Extract the values at those indices from the calculated features\n",
        "    selected_coords = normalized_coords[quantile_indices]\n",
        "    selected_elbow_velocity = elbow_velocity[quantile_indices]\n",
        "    selected_wrist_velocity = wrist_velocity[quantile_indices]\n",
        "    selected_rom_percentage = rom_percentage[quantile_indices]\n",
        "\n",
        "    # Combine selected features\n",
        "    features = np.column_stack([\n",
        "        selected_coords,\n",
        "        selected_elbow_velocity,\n",
        "        selected_wrist_velocity,\n",
        "        selected_rom_percentage\n",
        "    ])\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "pUhLthZVcVAX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_sets = load_all_processed_data(\"./processed_npzs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5adT03dTVG-U",
        "outputId": "a6be11fd-0988-4077-cbee-de0be14e4bf4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rep 0 shape for t5.mp4: (70, 4)\n",
            "Rep 1 shape for t5.mp4: (72, 4)\n",
            "Rep 2 shape for t5.mp4: (80, 4)\n",
            "Rep 3 shape for t5.mp4: (88, 4)\n",
            "Rep 4 shape for t5.mp4: (71, 4)\n",
            "Rep 5 shape for t5.mp4: (73, 4)\n",
            "Rep 6 shape for t5.mp4: (74, 4)\n",
            "Rep 7 shape for t5.mp4: (72, 4)\n",
            "Rep 8 shape for t5.mp4: (73, 4)\n",
            "Rep 9 shape for t5.mp4: (76, 4)\n",
            "Rep 10 shape for t5.mp4: (75, 4)\n",
            "Rep 11 shape for t5.mp4: (73, 4)\n",
            "Rep 12 shape for t5.mp4: (76, 4)\n",
            "Rep 13 shape for t5.mp4: (75, 4)\n",
            "Rep 14 shape for t5.mp4: (77, 4)\n",
            "Rep 15 shape for t5.mp4: (89, 4)\n",
            "Rep 16 shape for t5.mp4: (99, 4)\n",
            "Rep 17 shape for t5.mp4: (102, 4)\n",
            "Rep 18 shape for t5.mp4: (101, 4)\n",
            "Loaded 19 reps from t5.mp4\n",
            "Rep 0 shape for t1.mp4: (83, 4)\n",
            "Rep 1 shape for t1.mp4: (85, 4)\n",
            "Rep 2 shape for t1.mp4: (83, 4)\n",
            "Rep 3 shape for t1.mp4: (81, 4)\n",
            "Rep 4 shape for t1.mp4: (79, 4)\n",
            "Rep 5 shape for t1.mp4: (81, 4)\n",
            "Rep 6 shape for t1.mp4: (80, 4)\n",
            "Rep 7 shape for t1.mp4: (86, 4)\n",
            "Rep 8 shape for t1.mp4: (85, 4)\n",
            "Rep 9 shape for t1.mp4: (104, 4)\n",
            "Rep 10 shape for t1.mp4: (118, 4)\n",
            "Loaded 11 reps from t1.mp4\n",
            "Rep 0 shape for t2.mp4: (70, 4)\n",
            "Rep 1 shape for t2.mp4: (77, 4)\n",
            "Rep 2 shape for t2.mp4: (80, 4)\n",
            "Rep 3 shape for t2.mp4: (73, 4)\n",
            "Rep 4 shape for t2.mp4: (72, 4)\n",
            "Rep 5 shape for t2.mp4: (71, 4)\n",
            "Rep 6 shape for t2.mp4: (72, 4)\n",
            "Rep 7 shape for t2.mp4: (67, 4)\n",
            "Rep 8 shape for t2.mp4: (67, 4)\n",
            "Rep 9 shape for t2.mp4: (67, 4)\n",
            "Rep 10 shape for t2.mp4: (69, 4)\n",
            "Rep 11 shape for t2.mp4: (72, 4)\n",
            "Rep 12 shape for t2.mp4: (74, 4)\n",
            "Rep 13 shape for t2.mp4: (81, 4)\n",
            "Rep 14 shape for t2.mp4: (81, 4)\n",
            "Rep 15 shape for t2.mp4: (86, 4)\n",
            "Rep 16 shape for t2.mp4: (86, 4)\n",
            "Rep 17 shape for t2.mp4: (96, 4)\n",
            "Rep 18 shape for t2.mp4: (108, 4)\n",
            "Rep 19 shape for t2.mp4: (117, 4)\n",
            "Loaded 20 reps from t2.mp4\n",
            "Rep 0 shape for 5_l.mp4: (183, 4)\n",
            "Rep 1 shape for 5_l.mp4: (162, 4)\n",
            "Rep 2 shape for 5_l.mp4: (164, 4)\n",
            "Rep 3 shape for 5_l.mp4: (172, 4)\n",
            "Rep 4 shape for 5_l.mp4: (211, 4)\n",
            "Rep 5 shape for 5_l.mp4: (179, 4)\n",
            "Rep 6 shape for 5_l.mp4: (169, 4)\n",
            "Rep 7 shape for 5_l.mp4: (167, 4)\n",
            "Rep 8 shape for 5_l.mp4: (172, 4)\n",
            "Rep 9 shape for 5_l.mp4: (209, 4)\n",
            "Rep 10 shape for 5_l.mp4: (147, 4)\n",
            "Loaded 11 reps from 5_l.mp4\n",
            "Rep 0 shape for 14r (1).mp4: (148, 4)\n",
            "Rep 1 shape for 14r (1).mp4: (134, 4)\n",
            "Rep 2 shape for 14r (1).mp4: (123, 4)\n",
            "Rep 3 shape for 14r (1).mp4: (169, 4)\n",
            "Rep 4 shape for 14r (1).mp4: (262, 4)\n",
            "Rep 5 shape for 14r (1).mp4: (249, 4)\n",
            "Rep 6 shape for 14r (1).mp4: (391, 4)\n",
            "Rep 7 shape for 14r (1).mp4: (422, 4)\n",
            "Rep 8 shape for 14r (1).mp4: (315, 4)\n",
            "Loaded 9 reps from 14r (1).mp4\n",
            "Rep 0 shape for 11r (1).mp4: (121, 4)\n",
            "Rep 1 shape for 11r (1).mp4: (130, 4)\n",
            "Rep 2 shape for 11r (1).mp4: (175, 4)\n",
            "Rep 3 shape for 11r (1).mp4: (361, 4)\n",
            "Rep 4 shape for 11r (1).mp4: (300, 4)\n",
            "Loaded 5 reps from 11r (1).mp4\n",
            "Rep 0 shape for 12r (1).mp4: (74, 4)\n",
            "Rep 1 shape for 12r (1).mp4: (89, 4)\n",
            "Rep 2 shape for 12r (1).mp4: (96, 4)\n",
            "Rep 3 shape for 12r (1).mp4: (93, 4)\n",
            "Rep 4 shape for 12r (1).mp4: (100, 4)\n",
            "Rep 5 shape for 12r (1).mp4: (100, 4)\n",
            "Rep 6 shape for 12r (1).mp4: (114, 4)\n",
            "Rep 7 shape for 12r (1).mp4: (120, 4)\n",
            "Rep 8 shape for 12r (1).mp4: (113, 4)\n",
            "Rep 9 shape for 12r (1).mp4: (147, 4)\n",
            "Rep 10 shape for 12r (1).mp4: (160, 4)\n",
            "Rep 11 shape for 12r (1).mp4: (199, 4)\n",
            "Rep 12 shape for 12r (1).mp4: (144, 4)\n",
            "Rep 13 shape for 12r (1).mp4: (209, 4)\n",
            "Rep 14 shape for 12r (1).mp4: (181, 4)\n",
            "Rep 15 shape for 12r (1).mp4: (395, 4)\n",
            "Rep 16 shape for 12r (1).mp4: (238, 4)\n",
            "Rep 17 shape for 12r (1).mp4: (354, 4)\n",
            "Rep 18 shape for 12r (1).mp4: (303, 4)\n",
            "Rep 19 shape for 12r (1).mp4: (373, 4)\n",
            "Rep 20 shape for 12r (1).mp4: (367, 4)\n",
            "Loaded 21 reps from 12r (1).mp4\n",
            "Rep 0 shape for 5_r.mp4: (9, 4)\n",
            "Rep 1 shape for 5_r.mp4: (171, 4)\n",
            "Rep 2 shape for 5_r.mp4: (146, 4)\n",
            "Rep 3 shape for 5_r.mp4: (141, 4)\n",
            "Rep 4 shape for 5_r.mp4: (143, 4)\n",
            "Rep 5 shape for 5_r.mp4: (148, 4)\n",
            "Rep 6 shape for 5_r.mp4: (148, 4)\n",
            "Rep 7 shape for 5_r.mp4: (147, 4)\n",
            "Rep 8 shape for 5_r.mp4: (153, 4)\n",
            "Rep 9 shape for 5_r.mp4: (156, 4)\n",
            "Rep 10 shape for 5_r.mp4: (155, 4)\n",
            "Rep 11 shape for 5_r.mp4: (156, 4)\n",
            "Rep 12 shape for 5_r.mp4: (160, 4)\n",
            "Rep 13 shape for 5_r.mp4: (160, 4)\n",
            "Rep 14 shape for 5_r.mp4: (171, 4)\n",
            "Rep 15 shape for 5_r.mp4: (181, 4)\n",
            "Loaded 16 reps from 5_r.mp4\n",
            "Rep 0 shape for 10r (1).mp4: (167, 4)\n",
            "Rep 1 shape for 10r (1).mp4: (270, 4)\n",
            "Rep 2 shape for 10r (1).mp4: (264, 4)\n",
            "Loaded 3 reps from 10r (1).mp4\n",
            "Rep 0 shape for 8_r (1).mp4: (93, 4)\n",
            "Rep 1 shape for 8_r (1).mp4: (91, 4)\n",
            "Rep 2 shape for 8_r (1).mp4: (90, 4)\n",
            "Rep 3 shape for 8_r (1).mp4: (90, 4)\n",
            "Rep 4 shape for 8_r (1).mp4: (131, 4)\n",
            "Loaded 5 reps from 8_r (1).mp4\n",
            "Rep 0 shape for t4.mp4: (62, 4)\n",
            "Rep 1 shape for t4.mp4: (69, 4)\n",
            "Rep 2 shape for t4.mp4: (73, 4)\n",
            "Rep 3 shape for t4.mp4: (71, 4)\n",
            "Rep 4 shape for t4.mp4: (71, 4)\n",
            "Rep 5 shape for t4.mp4: (71, 4)\n",
            "Rep 6 shape for t4.mp4: (75, 4)\n",
            "Rep 7 shape for t4.mp4: (80, 4)\n",
            "Rep 8 shape for t4.mp4: (82, 4)\n",
            "Rep 9 shape for t4.mp4: (79, 4)\n",
            "Rep 10 shape for t4.mp4: (81, 4)\n",
            "Rep 11 shape for t4.mp4: (83, 4)\n",
            "Rep 12 shape for t4.mp4: (82, 4)\n",
            "Rep 13 shape for t4.mp4: (86, 4)\n",
            "Rep 14 shape for t4.mp4: (94, 4)\n",
            "Rep 15 shape for t4.mp4: (108, 4)\n",
            "Rep 16 shape for t4.mp4: (126, 4)\n",
            "Loaded 17 reps from t4.mp4\n",
            "Rep 0 shape for 6_l.mp4: (100, 4)\n",
            "Rep 1 shape for 6_l.mp4: (92, 4)\n",
            "Rep 2 shape for 6_l.mp4: (97, 4)\n",
            "Rep 3 shape for 6_l.mp4: (93, 4)\n",
            "Rep 4 shape for 6_l.mp4: (89, 4)\n",
            "Rep 5 shape for 6_l.mp4: (86, 4)\n",
            "Rep 6 shape for 6_l.mp4: (87, 4)\n",
            "Rep 7 shape for 6_l.mp4: (84, 4)\n",
            "Rep 8 shape for 6_l.mp4: (96, 4)\n",
            "Rep 9 shape for 6_l.mp4: (94, 4)\n",
            "Rep 10 shape for 6_l.mp4: (104, 4)\n",
            "Loaded 11 reps from 6_l.mp4\n",
            "Rep 0 shape for t6.mp4: (70, 4)\n",
            "Rep 1 shape for t6.mp4: (80, 4)\n",
            "Rep 2 shape for t6.mp4: (86, 4)\n",
            "Rep 3 shape for t6.mp4: (86, 4)\n",
            "Rep 4 shape for t6.mp4: (86, 4)\n",
            "Rep 5 shape for t6.mp4: (86, 4)\n",
            "Rep 6 shape for t6.mp4: (83, 4)\n",
            "Rep 7 shape for t6.mp4: (82, 4)\n",
            "Rep 8 shape for t6.mp4: (80, 4)\n",
            "Rep 9 shape for t6.mp4: (99, 4)\n",
            "Rep 10 shape for t6.mp4: (97, 4)\n",
            "Rep 11 shape for t6.mp4: (82, 4)\n",
            "Rep 12 shape for t6.mp4: (80, 4)\n",
            "Rep 13 shape for t6.mp4: (79, 4)\n",
            "Rep 14 shape for t6.mp4: (99, 4)\n",
            "Rep 15 shape for t6.mp4: (107, 4)\n",
            "Rep 16 shape for t6.mp4: (93, 4)\n",
            "Rep 17 shape for t6.mp4: (112, 4)\n",
            "Loaded 18 reps from t6.mp4\n",
            "Rep 0 shape for 9r (1).mp4: (127, 4)\n",
            "Rep 1 shape for 9r (1).mp4: (99, 4)\n",
            "Rep 2 shape for 9r (1).mp4: (106, 4)\n",
            "Rep 3 shape for 9r (1).mp4: (115, 4)\n",
            "Rep 4 shape for 9r (1).mp4: (126, 4)\n",
            "Rep 5 shape for 9r (1).mp4: (119, 4)\n",
            "Rep 6 shape for 9r (1).mp4: (115, 4)\n",
            "Rep 7 shape for 9r (1).mp4: (141, 4)\n",
            "Rep 8 shape for 9r (1).mp4: (132, 4)\n",
            "Rep 9 shape for 9r (1).mp4: (152, 4)\n",
            "Rep 10 shape for 9r (1).mp4: (169, 4)\n",
            "Rep 11 shape for 9r (1).mp4: (236, 4)\n",
            "Rep 12 shape for 9r (1).mp4: (227, 4)\n",
            "Loaded 13 reps from 9r (1).mp4\n",
            "Rep 0 shape for 7_r (1).mp4: (96, 4)\n",
            "Rep 1 shape for 7_r (1).mp4: (89, 4)\n",
            "Rep 2 shape for 7_r (1).mp4: (91, 4)\n",
            "Rep 3 shape for 7_r (1).mp4: (97, 4)\n",
            "Rep 4 shape for 7_r (1).mp4: (115, 4)\n",
            "Loaded 5 reps from 7_r (1).mp4\n",
            "Rep 0 shape for t3.mp4: (62, 4)\n",
            "Rep 1 shape for t3.mp4: (73, 4)\n",
            "Rep 2 shape for t3.mp4: (73, 4)\n",
            "Rep 3 shape for t3.mp4: (79, 4)\n",
            "Rep 4 shape for t3.mp4: (75, 4)\n",
            "Rep 5 shape for t3.mp4: (75, 4)\n",
            "Rep 6 shape for t3.mp4: (74, 4)\n",
            "Rep 7 shape for t3.mp4: (72, 4)\n",
            "Rep 8 shape for t3.mp4: (76, 4)\n",
            "Rep 9 shape for t3.mp4: (81, 4)\n",
            "Rep 10 shape for t3.mp4: (85, 4)\n",
            "Rep 11 shape for t3.mp4: (109, 4)\n",
            "Loaded 12 reps from t3.mp4\n",
            "Rep 0 shape for 13r (1).mp4: (128, 4)\n",
            "Rep 1 shape for 13r (1).mp4: (132, 4)\n",
            "Rep 2 shape for 13r (1).mp4: (131, 4)\n",
            "Rep 3 shape for 13r (1).mp4: (130, 4)\n",
            "Rep 4 shape for 13r (1).mp4: (204, 4)\n",
            "Rep 5 shape for 13r (1).mp4: (218, 4)\n",
            "Rep 6 shape for 13r (1).mp4: (266, 4)\n",
            "Rep 7 shape for 13r (1).mp4: (382, 4)\n",
            "Rep 8 shape for 13r (1).mp4: (405, 4)\n",
            "Rep 9 shape for 13r (1).mp4: (444, 4)\n",
            "Loaded 10 reps from 13r (1).mp4\n",
            "Rep 0 shape for 4_r.mp4: (76, 4)\n",
            "Rep 1 shape for 4_r.mp4: (73, 4)\n",
            "Rep 2 shape for 4_r.mp4: (68, 4)\n",
            "Rep 3 shape for 4_r.mp4: (71, 4)\n",
            "Rep 4 shape for 4_r.mp4: (75, 4)\n",
            "Rep 5 shape for 4_r.mp4: (70, 4)\n",
            "Rep 6 shape for 4_r.mp4: (72, 4)\n",
            "Rep 7 shape for 4_r.mp4: (71, 4)\n",
            "Rep 8 shape for 4_r.mp4: (71, 4)\n",
            "Rep 9 shape for 4_r.mp4: (72, 4)\n",
            "Rep 10 shape for 4_r.mp4: (77, 4)\n",
            "Rep 11 shape for 4_r.mp4: (81, 4)\n",
            "Rep 12 shape for 4_r.mp4: (106, 4)\n",
            "Rep 13 shape for 4_r.mp4: (116, 4)\n",
            "Loaded 14 reps from 4_r.mp4\n",
            "Rep 0 shape for IMG_5711.mov.mp4: (88, 4)\n",
            "Rep 1 shape for IMG_5711.mov.mp4: (74, 4)\n",
            "Rep 2 shape for IMG_5711.mov.mp4: (76, 4)\n",
            "Rep 3 shape for IMG_5711.mov.mp4: (71, 4)\n",
            "Rep 4 shape for IMG_5711.mov.mp4: (73, 4)\n",
            "Rep 5 shape for IMG_5711.mov.mp4: (71, 4)\n",
            "Rep 6 shape for IMG_5711.mov.mp4: (70, 4)\n",
            "Rep 7 shape for IMG_5711.mov.mp4: (69, 4)\n",
            "Rep 8 shape for IMG_5711.mov.mp4: (72, 4)\n",
            "Rep 9 shape for IMG_5711.mov.mp4: (67, 4)\n",
            "Rep 10 shape for IMG_5711.mov.mp4: (72, 4)\n",
            "Rep 11 shape for IMG_5711.mov.mp4: (74, 4)\n",
            "Rep 12 shape for IMG_5711.mov.mp4: (80, 4)\n",
            "Rep 13 shape for IMG_5711.mov.mp4: (84, 4)\n",
            "Rep 14 shape for IMG_5711.mov.mp4: (99, 4)\n",
            "Rep 15 shape for IMG_5711.mov.mp4: (112, 4)\n",
            "Rep 16 shape for IMG_5711.mov.mp4: (127, 4)\n",
            "Rep 17 shape for IMG_5711.mov.mp4: (162, 4)\n",
            "Rep 18 shape for IMG_5711.mov.mp4: (220, 4)\n",
            "Loaded 19 reps from IMG_5711.mov.mp4\n",
            "Rep 0 shape for IMG_5712.mov.mp4: (68, 4)\n",
            "Rep 1 shape for IMG_5712.mov.mp4: (77, 4)\n",
            "Rep 2 shape for IMG_5712.mov.mp4: (67, 4)\n",
            "Rep 3 shape for IMG_5712.mov.mp4: (69, 4)\n",
            "Rep 4 shape for IMG_5712.mov.mp4: (69, 4)\n",
            "Rep 5 shape for IMG_5712.mov.mp4: (70, 4)\n",
            "Rep 6 shape for IMG_5712.mov.mp4: (78, 4)\n",
            "Rep 7 shape for IMG_5712.mov.mp4: (81, 4)\n",
            "Rep 8 shape for IMG_5712.mov.mp4: (87, 4)\n",
            "Rep 9 shape for IMG_5712.mov.mp4: (87, 4)\n",
            "Rep 10 shape for IMG_5712.mov.mp4: (116, 4)\n",
            "Rep 11 shape for IMG_5712.mov.mp4: (116, 4)\n",
            "Rep 12 shape for IMG_5712.mov.mp4: (125, 4)\n",
            "Rep 13 shape for IMG_5712.mov.mp4: (104, 4)\n",
            "Rep 14 shape for IMG_5712.mov.mp4: (157, 4)\n",
            "Rep 15 shape for IMG_5712.mov.mp4: (147, 4)\n",
            "Rep 16 shape for IMG_5712.mov.mp4: (178, 4)\n",
            "Rep 17 shape for IMG_5712.mov.mp4: (123, 4)\n",
            "Rep 18 shape for IMG_5712.mov.mp4: (217, 4)\n",
            "Rep 19 shape for IMG_5712.mov.mp4: (201, 4)\n",
            "Rep 20 shape for IMG_5712.mov.mp4: (216, 4)\n",
            "Loaded 21 reps from IMG_5712.mov.mp4\n",
            "Rep 0 shape for IMG_5714.mov.mp4: (82, 4)\n",
            "Rep 1 shape for IMG_5714.mov.mp4: (87, 4)\n",
            "Rep 2 shape for IMG_5714.mov.mp4: (91, 4)\n",
            "Rep 3 shape for IMG_5714.mov.mp4: (92, 4)\n",
            "Rep 4 shape for IMG_5714.mov.mp4: (94, 4)\n",
            "Rep 5 shape for IMG_5714.mov.mp4: (95, 4)\n",
            "Rep 6 shape for IMG_5714.mov.mp4: (98, 4)\n",
            "Rep 7 shape for IMG_5714.mov.mp4: (93, 4)\n",
            "Rep 8 shape for IMG_5714.mov.mp4: (98, 4)\n",
            "Rep 9 shape for IMG_5714.mov.mp4: (123, 4)\n",
            "Rep 10 shape for IMG_5714.mov.mp4: (99, 4)\n",
            "Rep 11 shape for IMG_5714.mov.mp4: (102, 4)\n",
            "Rep 12 shape for IMG_5714.mov.mp4: (111, 4)\n",
            "Rep 13 shape for IMG_5714.mov.mp4: (151, 4)\n",
            "Rep 14 shape for IMG_5714.mov.mp4: (128, 4)\n",
            "Rep 15 shape for IMG_5714.mov.mp4: (114, 4)\n",
            "Rep 16 shape for IMG_5714.mov.mp4: (163, 4)\n",
            "Rep 17 shape for IMG_5714.mov.mp4: (165, 4)\n",
            "Loaded 18 reps from IMG_5714.mov.mp4\n",
            "Rep 0 shape for IMG_5713.mov.mp4: (99, 4)\n",
            "Rep 1 shape for IMG_5713.mov.mp4: (80, 4)\n",
            "Rep 2 shape for IMG_5713.mov.mp4: (79, 4)\n",
            "Rep 3 shape for IMG_5713.mov.mp4: (87, 4)\n",
            "Rep 4 shape for IMG_5713.mov.mp4: (88, 4)\n",
            "Rep 5 shape for IMG_5713.mov.mp4: (85, 4)\n",
            "Rep 6 shape for IMG_5713.mov.mp4: (83, 4)\n",
            "Rep 7 shape for IMG_5713.mov.mp4: (81, 4)\n",
            "Rep 8 shape for IMG_5713.mov.mp4: (74, 4)\n",
            "Rep 9 shape for IMG_5713.mov.mp4: (76, 4)\n",
            "Rep 10 shape for IMG_5713.mov.mp4: (82, 4)\n",
            "Rep 11 shape for IMG_5713.mov.mp4: (84, 4)\n",
            "Rep 12 shape for IMG_5713.mov.mp4: (80, 4)\n",
            "Rep 13 shape for IMG_5713.mov.mp4: (82, 4)\n",
            "Rep 14 shape for IMG_5713.mov.mp4: (83, 4)\n",
            "Rep 15 shape for IMG_5713.mov.mp4: (83, 4)\n",
            "Rep 16 shape for IMG_5713.mov.mp4: (87, 4)\n",
            "Rep 17 shape for IMG_5713.mov.mp4: (83, 4)\n",
            "Rep 18 shape for IMG_5713.mov.mp4: (87, 4)\n",
            "Rep 19 shape for IMG_5713.mov.mp4: (93, 4)\n",
            "Rep 20 shape for IMG_5713.mov.mp4: (85, 4)\n",
            "Rep 21 shape for IMG_5713.mov.mp4: (91, 4)\n",
            "Rep 22 shape for IMG_5713.mov.mp4: (96, 4)\n",
            "Rep 23 shape for IMG_5713.mov.mp4: (95, 4)\n",
            "Rep 24 shape for IMG_5713.mov.mp4: (97, 4)\n",
            "Rep 25 shape for IMG_5713.mov.mp4: (114, 4)\n",
            "Rep 26 shape for IMG_5713.mov.mp4: (111, 4)\n",
            "Rep 27 shape for IMG_5713.mov.mp4: (107, 4)\n",
            "Rep 28 shape for IMG_5713.mov.mp4: (153, 4)\n",
            "Rep 29 shape for IMG_5713.mov.mp4: (101, 4)\n",
            "Rep 30 shape for IMG_5713.mov.mp4: (143, 4)\n",
            "Rep 31 shape for IMG_5713.mov.mp4: (123, 4)\n",
            "Rep 32 shape for IMG_5713.mov.mp4: (111, 4)\n",
            "Rep 33 shape for IMG_5713.mov.mp4: (139, 4)\n",
            "Rep 34 shape for IMG_5713.mov.mp4: (116, 4)\n",
            "Rep 35 shape for IMG_5713.mov.mp4: (128, 4)\n",
            "Rep 36 shape for IMG_5713.mov.mp4: (115, 4)\n",
            "Loaded 37 reps from IMG_5713.mov.mp4\n",
            "Rep 0 shape for IMG_5717.mov.mp4: (78, 4)\n",
            "Rep 1 shape for IMG_5717.mov.mp4: (93, 4)\n",
            "Rep 2 shape for IMG_5717.mov.mp4: (87, 4)\n",
            "Rep 3 shape for IMG_5717.mov.mp4: (92, 4)\n",
            "Rep 4 shape for IMG_5717.mov.mp4: (94, 4)\n",
            "Rep 5 shape for IMG_5717.mov.mp4: (99, 4)\n",
            "Rep 6 shape for IMG_5717.mov.mp4: (96, 4)\n",
            "Rep 7 shape for IMG_5717.mov.mp4: (135, 4)\n",
            "Rep 8 shape for IMG_5717.mov.mp4: (117, 4)\n",
            "Rep 9 shape for IMG_5717.mov.mp4: (137, 4)\n",
            "Rep 10 shape for IMG_5717.mov.mp4: (162, 4)\n",
            "Rep 11 shape for IMG_5717.mov.mp4: (140, 4)\n",
            "Rep 12 shape for IMG_5717.mov.mp4: (205, 4)\n",
            "Loaded 13 reps from IMG_5717.mov.mp4\n",
            "Rep 0 shape for IMG_5715.mov.mp4: (80, 4)\n",
            "Rep 1 shape for IMG_5715.mov.mp4: (79, 4)\n",
            "Rep 2 shape for IMG_5715.mov.mp4: (85, 4)\n",
            "Rep 3 shape for IMG_5715.mov.mp4: (86, 4)\n",
            "Rep 4 shape for IMG_5715.mov.mp4: (97, 4)\n",
            "Rep 5 shape for IMG_5715.mov.mp4: (95, 4)\n",
            "Rep 6 shape for IMG_5715.mov.mp4: (96, 4)\n",
            "Rep 7 shape for IMG_5715.mov.mp4: (104, 4)\n",
            "Rep 8 shape for IMG_5715.mov.mp4: (117, 4)\n",
            "Rep 9 shape for IMG_5715.mov.mp4: (106, 4)\n",
            "Rep 10 shape for IMG_5715.mov.mp4: (114, 4)\n",
            "Rep 11 shape for IMG_5715.mov.mp4: (115, 4)\n",
            "Rep 12 shape for IMG_5715.mov.mp4: (110, 4)\n",
            "Rep 13 shape for IMG_5715.mov.mp4: (133, 4)\n",
            "Rep 14 shape for IMG_5715.mov.mp4: (134, 4)\n",
            "Rep 15 shape for IMG_5715.mov.mp4: (179, 4)\n",
            "Rep 16 shape for IMG_5715.mov.mp4: (193, 4)\n",
            "Loaded 17 reps from IMG_5715.mov.mp4\n",
            "Rep 0 shape for IMG_5704.mov.mp4: (85, 4)\n",
            "Rep 1 shape for IMG_5704.mov.mp4: (77, 4)\n",
            "Rep 2 shape for IMG_5704.mov.mp4: (82, 4)\n",
            "Rep 3 shape for IMG_5704.mov.mp4: (118, 4)\n",
            "Rep 4 shape for IMG_5704.mov.mp4: (91, 4)\n",
            "Rep 5 shape for IMG_5704.mov.mp4: (91, 4)\n",
            "Rep 6 shape for IMG_5704.mov.mp4: (90, 4)\n",
            "Rep 7 shape for IMG_5704.mov.mp4: (103, 4)\n",
            "Rep 8 shape for IMG_5704.mov.mp4: (97, 4)\n",
            "Rep 9 shape for IMG_5704.mov.mp4: (86, 4)\n",
            "Loaded 10 reps from IMG_5704.mov.mp4\n",
            "Rep 0 shape for IMG_5706.mov.mp4: (254, 4)\n",
            "Rep 1 shape for IMG_5706.mov.mp4: (204, 4)\n",
            "Rep 2 shape for IMG_5706.mov.mp4: (106, 4)\n",
            "Rep 3 shape for IMG_5706.mov.mp4: (99, 4)\n",
            "Rep 4 shape for IMG_5706.mov.mp4: (140, 4)\n",
            "Rep 5 shape for IMG_5706.mov.mp4: (118, 4)\n",
            "Rep 6 shape for IMG_5706.mov.mp4: (125, 4)\n",
            "Rep 7 shape for IMG_5706.mov.mp4: (174, 4)\n",
            "Rep 8 shape for IMG_5706.mov.mp4: (148, 4)\n",
            "Rep 9 shape for IMG_5706.mov.mp4: (115, 4)\n",
            "Rep 10 shape for IMG_5706.mov.mp4: (351, 4)\n",
            "Loaded 11 reps from IMG_5706.mov.mp4\n",
            "Rep 0 shape for IMG_5705.mov.mp4: (69, 4)\n",
            "Rep 1 shape for IMG_5705.mov.mp4: (77, 4)\n",
            "Rep 2 shape for IMG_5705.mov.mp4: (75, 4)\n",
            "Rep 3 shape for IMG_5705.mov.mp4: (67, 4)\n",
            "Rep 4 shape for IMG_5705.mov.mp4: (68, 4)\n",
            "Rep 5 shape for IMG_5705.mov.mp4: (67, 4)\n",
            "Rep 6 shape for IMG_5705.mov.mp4: (71, 4)\n",
            "Rep 7 shape for IMG_5705.mov.mp4: (73, 4)\n",
            "Rep 8 shape for IMG_5705.mov.mp4: (72, 4)\n",
            "Rep 9 shape for IMG_5705.mov.mp4: (68, 4)\n",
            "Rep 10 shape for IMG_5705.mov.mp4: (66, 4)\n",
            "Rep 11 shape for IMG_5705.mov.mp4: (66, 4)\n",
            "Rep 12 shape for IMG_5705.mov.mp4: (66, 4)\n",
            "Rep 13 shape for IMG_5705.mov.mp4: (70, 4)\n",
            "Rep 14 shape for IMG_5705.mov.mp4: (70, 4)\n",
            "Rep 15 shape for IMG_5705.mov.mp4: (69, 4)\n",
            "Rep 16 shape for IMG_5705.mov.mp4: (80, 4)\n",
            "Rep 17 shape for IMG_5705.mov.mp4: (76, 4)\n",
            "Rep 18 shape for IMG_5705.mov.mp4: (89, 4)\n",
            "Rep 19 shape for IMG_5705.mov.mp4: (103, 4)\n",
            "Rep 20 shape for IMG_5705.mov.mp4: (404, 4)\n",
            "Loaded 21 reps from IMG_5705.mov.mp4\n",
            "Rep 0 shape for IMG_5703.mov.mp4: (71, 4)\n",
            "Rep 1 shape for IMG_5703.mov.mp4: (67, 4)\n",
            "Rep 2 shape for IMG_5703.mov.mp4: (67, 4)\n",
            "Rep 3 shape for IMG_5703.mov.mp4: (67, 4)\n",
            "Rep 4 shape for IMG_5703.mov.mp4: (72, 4)\n",
            "Rep 5 shape for IMG_5703.mov.mp4: (75, 4)\n",
            "Rep 6 shape for IMG_5703.mov.mp4: (80, 4)\n",
            "Rep 7 shape for IMG_5703.mov.mp4: (88, 4)\n",
            "Rep 8 shape for IMG_5703.mov.mp4: (89, 4)\n",
            "Rep 9 shape for IMG_5703.mov.mp4: (95, 4)\n",
            "Rep 10 shape for IMG_5703.mov.mp4: (83, 4)\n",
            "Rep 11 shape for IMG_5703.mov.mp4: (94, 4)\n",
            "Loaded 12 reps from IMG_5703.mov.mp4\n",
            "Rep 0 shape for IMG_5707.mov.mp4: (77, 4)\n",
            "Rep 1 shape for IMG_5707.mov.mp4: (81, 4)\n",
            "Rep 2 shape for IMG_5707.mov.mp4: (79, 4)\n",
            "Rep 3 shape for IMG_5707.mov.mp4: (71, 4)\n",
            "Rep 4 shape for IMG_5707.mov.mp4: (71, 4)\n",
            "Rep 5 shape for IMG_5707.mov.mp4: (73, 4)\n",
            "Rep 6 shape for IMG_5707.mov.mp4: (74, 4)\n",
            "Rep 7 shape for IMG_5707.mov.mp4: (78, 4)\n",
            "Rep 8 shape for IMG_5707.mov.mp4: (79, 4)\n",
            "Rep 9 shape for IMG_5707.mov.mp4: (76, 4)\n",
            "Rep 10 shape for IMG_5707.mov.mp4: (79, 4)\n",
            "Rep 11 shape for IMG_5707.mov.mp4: (104, 4)\n",
            "Rep 12 shape for IMG_5707.mov.mp4: (138, 4)\n",
            "Rep 13 shape for IMG_5707.mov.mp4: (133, 4)\n",
            "Rep 14 shape for IMG_5707.mov.mp4: (196, 4)\n",
            "Rep 15 shape for IMG_5707.mov.mp4: (162, 4)\n",
            "Rep 16 shape for IMG_5707.mov.mp4: (145, 4)\n",
            "Rep 17 shape for IMG_5707.mov.mp4: (257, 4)\n",
            "Loaded 18 reps from IMG_5707.mov.mp4\n",
            "Rep 0 shape for IMG_5708.mov.mp4: (80, 4)\n",
            "Rep 1 shape for IMG_5708.mov.mp4: (76, 4)\n",
            "Rep 2 shape for IMG_5708.mov.mp4: (81, 4)\n",
            "Rep 3 shape for IMG_5708.mov.mp4: (81, 4)\n",
            "Rep 4 shape for IMG_5708.mov.mp4: (78, 4)\n",
            "Rep 5 shape for IMG_5708.mov.mp4: (84, 4)\n",
            "Rep 6 shape for IMG_5708.mov.mp4: (116, 4)\n",
            "Rep 7 shape for IMG_5708.mov.mp4: (109, 4)\n",
            "Rep 8 shape for IMG_5708.mov.mp4: (121, 4)\n",
            "Rep 9 shape for IMG_5708.mov.mp4: (132, 4)\n",
            "Rep 10 shape for IMG_5708.mov.mp4: (109, 4)\n",
            "Rep 11 shape for IMG_5708.mov.mp4: (156, 4)\n",
            "Rep 12 shape for IMG_5708.mov.mp4: (173, 4)\n",
            "Rep 13 shape for IMG_5708.mov.mp4: (161, 4)\n",
            "Loaded 14 reps from IMG_5708.mov.mp4\n",
            "Rep 0 shape for IMG_5718.mov.mp4: (69, 4)\n",
            "Rep 1 shape for IMG_5718.mov.mp4: (72, 4)\n",
            "Rep 2 shape for IMG_5718.mov.mp4: (73, 4)\n",
            "Rep 3 shape for IMG_5718.mov.mp4: (72, 4)\n",
            "Rep 4 shape for IMG_5718.mov.mp4: (67, 4)\n",
            "Rep 5 shape for IMG_5718.mov.mp4: (69, 4)\n",
            "Rep 6 shape for IMG_5718.mov.mp4: (76, 4)\n",
            "Rep 7 shape for IMG_5718.mov.mp4: (76, 4)\n",
            "Rep 8 shape for IMG_5718.mov.mp4: (83, 4)\n",
            "Rep 9 shape for IMG_5718.mov.mp4: (102, 4)\n",
            "Rep 10 shape for IMG_5718.mov.mp4: (94, 4)\n",
            "Rep 11 shape for IMG_5718.mov.mp4: (105, 4)\n",
            "Rep 12 shape for IMG_5718.mov.mp4: (105, 4)\n",
            "Rep 13 shape for IMG_5718.mov.mp4: (116, 4)\n",
            "Rep 14 shape for IMG_5718.mov.mp4: (129, 4)\n",
            "Rep 15 shape for IMG_5718.mov.mp4: (165, 4)\n",
            "Rep 16 shape for IMG_5718.mov.mp4: (245, 4)\n",
            "Loaded 17 reps from IMG_5718.mov.mp4\n",
            "Rep 0 shape for IMG_5722.mov.mp4: (65, 4)\n",
            "Rep 1 shape for IMG_5722.mov.mp4: (75, 4)\n",
            "Rep 2 shape for IMG_5722.mov.mp4: (81, 4)\n",
            "Rep 3 shape for IMG_5722.mov.mp4: (78, 4)\n",
            "Rep 4 shape for IMG_5722.mov.mp4: (82, 4)\n",
            "Rep 5 shape for IMG_5722.mov.mp4: (79, 4)\n",
            "Rep 6 shape for IMG_5722.mov.mp4: (80, 4)\n",
            "Rep 7 shape for IMG_5722.mov.mp4: (111, 4)\n",
            "Rep 8 shape for IMG_5722.mov.mp4: (93, 4)\n",
            "Rep 9 shape for IMG_5722.mov.mp4: (82, 4)\n",
            "Rep 10 shape for IMG_5722.mov.mp4: (92, 4)\n",
            "Rep 11 shape for IMG_5722.mov.mp4: (102, 4)\n",
            "Rep 12 shape for IMG_5722.mov.mp4: (117, 4)\n",
            "Rep 13 shape for IMG_5722.mov.mp4: (113, 4)\n",
            "Rep 14 shape for IMG_5722.mov.mp4: (125, 4)\n",
            "Rep 15 shape for IMG_5722.mov.mp4: (125, 4)\n",
            "Rep 16 shape for IMG_5722.mov.mp4: (126, 4)\n",
            "Rep 17 shape for IMG_5722.mov.mp4: (124, 4)\n",
            "Rep 18 shape for IMG_5722.mov.mp4: (128, 4)\n",
            "Rep 19 shape for IMG_5722.mov.mp4: (141, 4)\n",
            "Loaded 20 reps from IMG_5722.mov.mp4\n",
            "Rep 0 shape for IMG_5721.mov.mp4: (71, 4)\n",
            "Rep 1 shape for IMG_5721.mov.mp4: (83, 4)\n",
            "Rep 2 shape for IMG_5721.mov.mp4: (88, 4)\n",
            "Rep 3 shape for IMG_5721.mov.mp4: (84, 4)\n",
            "Rep 4 shape for IMG_5721.mov.mp4: (82, 4)\n",
            "Rep 5 shape for IMG_5721.mov.mp4: (80, 4)\n",
            "Rep 6 shape for IMG_5721.mov.mp4: (84, 4)\n",
            "Rep 7 shape for IMG_5721.mov.mp4: (84, 4)\n",
            "Rep 8 shape for IMG_5721.mov.mp4: (94, 4)\n",
            "Rep 9 shape for IMG_5721.mov.mp4: (78, 4)\n",
            "Rep 10 shape for IMG_5721.mov.mp4: (81, 4)\n",
            "Rep 11 shape for IMG_5721.mov.mp4: (85, 4)\n",
            "Rep 12 shape for IMG_5721.mov.mp4: (85, 4)\n",
            "Rep 13 shape for IMG_5721.mov.mp4: (85, 4)\n",
            "Rep 14 shape for IMG_5721.mov.mp4: (87, 4)\n",
            "Rep 15 shape for IMG_5721.mov.mp4: (95, 4)\n",
            "Rep 16 shape for IMG_5721.mov.mp4: (91, 4)\n",
            "Rep 17 shape for IMG_5721.mov.mp4: (99, 4)\n",
            "Rep 18 shape for IMG_5721.mov.mp4: (97, 4)\n",
            "Rep 19 shape for IMG_5721.mov.mp4: (105, 4)\n",
            "Rep 20 shape for IMG_5721.mov.mp4: (112, 4)\n",
            "Rep 21 shape for IMG_5721.mov.mp4: (106, 4)\n",
            "Rep 22 shape for IMG_5721.mov.mp4: (132, 4)\n",
            "Rep 23 shape for IMG_5721.mov.mp4: (145, 4)\n",
            "Loaded 24 reps from IMG_5721.mov.mp4\n",
            "Rep 0 shape for IMG_5720.mov.mp4: (79, 4)\n",
            "Rep 1 shape for IMG_5720.mov.mp4: (79, 4)\n",
            "Rep 2 shape for IMG_5720.mov.mp4: (81, 4)\n",
            "Rep 3 shape for IMG_5720.mov.mp4: (73, 4)\n",
            "Rep 4 shape for IMG_5720.mov.mp4: (86, 4)\n",
            "Rep 5 shape for IMG_5720.mov.mp4: (86, 4)\n",
            "Rep 6 shape for IMG_5720.mov.mp4: (120, 4)\n",
            "Rep 7 shape for IMG_5720.mov.mp4: (117, 4)\n",
            "Rep 8 shape for IMG_5720.mov.mp4: (144, 4)\n",
            "Rep 9 shape for IMG_5720.mov.mp4: (117, 4)\n",
            "Rep 10 shape for IMG_5720.mov.mp4: (154, 4)\n",
            "Loaded 11 reps from IMG_5720.mov.mp4\n",
            "Rep 0 shape for IMG_5723.mov.mp4: (75, 4)\n",
            "Rep 1 shape for IMG_5723.mov.mp4: (72, 4)\n",
            "Rep 2 shape for IMG_5723.mov.mp4: (68, 4)\n",
            "Rep 3 shape for IMG_5723.mov.mp4: (74, 4)\n",
            "Rep 4 shape for IMG_5723.mov.mp4: (71, 4)\n",
            "Rep 5 shape for IMG_5723.mov.mp4: (80, 4)\n",
            "Rep 6 shape for IMG_5723.mov.mp4: (79, 4)\n",
            "Rep 7 shape for IMG_5723.mov.mp4: (84, 4)\n",
            "Rep 8 shape for IMG_5723.mov.mp4: (98, 4)\n",
            "Rep 9 shape for IMG_5723.mov.mp4: (119, 4)\n",
            "Rep 10 shape for IMG_5723.mov.mp4: (144, 4)\n",
            "Loaded 11 reps from IMG_5723.mov.mp4\n",
            "Rep 0 shape for IMG_5724.mov.mp4: (113, 4)\n",
            "Rep 1 shape for IMG_5724.mov.mp4: (109, 4)\n",
            "Rep 2 shape for IMG_5724.mov.mp4: (166, 4)\n",
            "Loaded 3 reps from IMG_5724.mov.mp4\n",
            "Rep 0 shape for IMG_5725.mov.mp4: (100, 4)\n",
            "Rep 1 shape for IMG_5725.mov.mp4: (110, 4)\n",
            "Rep 2 shape for IMG_5725.mov.mp4: (111, 4)\n",
            "Loaded 3 reps from IMG_5725.mov.mp4\n",
            "Rep 0 shape for IMG_5726.mov.mp4: (82, 4)\n",
            "Rep 1 shape for IMG_5726.mov.mp4: (75, 4)\n",
            "Rep 2 shape for IMG_5726.mov.mp4: (80, 4)\n",
            "Rep 3 shape for IMG_5726.mov.mp4: (72, 4)\n",
            "Rep 4 shape for IMG_5726.mov.mp4: (74, 4)\n",
            "Rep 5 shape for IMG_5726.mov.mp4: (80, 4)\n",
            "Rep 6 shape for IMG_5726.mov.mp4: (85, 4)\n",
            "Rep 7 shape for IMG_5726.mov.mp4: (85, 4)\n",
            "Rep 8 shape for IMG_5726.mov.mp4: (105, 4)\n",
            "Rep 9 shape for IMG_5726.mov.mp4: (131, 4)\n",
            "Rep 10 shape for IMG_5726.mov.mp4: (162, 4)\n",
            "Rep 11 shape for IMG_5726.mov.mp4: (141, 4)\n",
            "Rep 12 shape for IMG_5726.mov.mp4: (177, 4)\n",
            "Loaded 13 reps from IMG_5726.mov.mp4\n",
            "Rep 0 shape for IMG_5727.mov.mp4: (146, 4)\n",
            "Rep 1 shape for IMG_5727.mov.mp4: (200, 4)\n",
            "Rep 2 shape for IMG_5727.mov.mp4: (241, 4)\n",
            "Loaded 3 reps from IMG_5727.mov.mp4\n",
            "Rep 0 shape for IMG_5728.mov.mp4: (103, 4)\n",
            "Rep 1 shape for IMG_5728.mov.mp4: (200, 4)\n",
            "Rep 2 shape for IMG_5728.mov.mp4: (167, 4)\n",
            "Loaded 3 reps from IMG_5728.mov.mp4\n",
            "Rep 0 shape for IMG_5729.mov.mp4: (93, 4)\n",
            "Rep 1 shape for IMG_5729.mov.mp4: (104, 4)\n",
            "Rep 2 shape for IMG_5729.mov.mp4: (117, 4)\n",
            "Rep 3 shape for IMG_5729.mov.mp4: (147, 4)\n",
            "Rep 4 shape for IMG_5729.mov.mp4: (725, 4)\n",
            "Loaded 5 reps from IMG_5729.mov.mp4\n",
            "Rep 0 shape for IMG_5732.mov.mp4: (86, 4)\n",
            "Rep 1 shape for IMG_5732.mov.mp4: (96, 4)\n",
            "Rep 2 shape for IMG_5732.mov.mp4: (85, 4)\n",
            "Rep 3 shape for IMG_5732.mov.mp4: (95, 4)\n",
            "Rep 4 shape for IMG_5732.mov.mp4: (99, 4)\n",
            "Rep 5 shape for IMG_5732.mov.mp4: (101, 4)\n",
            "Rep 6 shape for IMG_5732.mov.mp4: (96, 4)\n",
            "Rep 7 shape for IMG_5732.mov.mp4: (101, 4)\n",
            "Rep 8 shape for IMG_5732.mov.mp4: (95, 4)\n",
            "Rep 9 shape for IMG_5732.mov.mp4: (93, 4)\n",
            "Rep 10 shape for IMG_5732.mov.mp4: (97, 4)\n",
            "Rep 11 shape for IMG_5732.mov.mp4: (112, 4)\n",
            "Rep 12 shape for IMG_5732.mov.mp4: (110, 4)\n",
            "Rep 13 shape for IMG_5732.mov.mp4: (98, 4)\n",
            "Rep 14 shape for IMG_5732.mov.mp4: (116, 4)\n",
            "Rep 15 shape for IMG_5732.mov.mp4: (136, 4)\n",
            "Loaded 16 reps from IMG_5732.mov.mp4\n",
            "Rep 0 shape for IMG_5731.mov.mp4: (86, 4)\n",
            "Rep 1 shape for IMG_5731.mov.mp4: (82, 4)\n",
            "Rep 2 shape for IMG_5731.mov.mp4: (82, 4)\n",
            "Rep 3 shape for IMG_5731.mov.mp4: (78, 4)\n",
            "Rep 4 shape for IMG_5731.mov.mp4: (77, 4)\n",
            "Rep 5 shape for IMG_5731.mov.mp4: (77, 4)\n",
            "Rep 6 shape for IMG_5731.mov.mp4: (91, 4)\n",
            "Rep 7 shape for IMG_5731.mov.mp4: (116, 4)\n",
            "Rep 8 shape for IMG_5731.mov.mp4: (82, 4)\n",
            "Rep 9 shape for IMG_5731.mov.mp4: (82, 4)\n",
            "Rep 10 shape for IMG_5731.mov.mp4: (78, 4)\n",
            "Rep 11 shape for IMG_5731.mov.mp4: (88, 4)\n",
            "Rep 12 shape for IMG_5731.mov.mp4: (84, 4)\n",
            "Rep 13 shape for IMG_5731.mov.mp4: (82, 4)\n",
            "Rep 14 shape for IMG_5731.mov.mp4: (82, 4)\n",
            "Rep 15 shape for IMG_5731.mov.mp4: (86, 4)\n",
            "Rep 16 shape for IMG_5731.mov.mp4: (89, 4)\n",
            "Rep 17 shape for IMG_5731.mov.mp4: (90, 4)\n",
            "Rep 18 shape for IMG_5731.mov.mp4: (87, 4)\n",
            "Rep 19 shape for IMG_5731.mov.mp4: (85, 4)\n",
            "Rep 20 shape for IMG_5731.mov.mp4: (89, 4)\n",
            "Rep 21 shape for IMG_5731.mov.mp4: (86, 4)\n",
            "Rep 22 shape for IMG_5731.mov.mp4: (81, 4)\n",
            "Rep 23 shape for IMG_5731.mov.mp4: (85, 4)\n",
            "Rep 24 shape for IMG_5731.mov.mp4: (199, 4)\n",
            "Rep 25 shape for IMG_5731.mov.mp4: (129, 4)\n",
            "Rep 26 shape for IMG_5731.mov.mp4: (113, 4)\n",
            "Rep 27 shape for IMG_5731.mov.mp4: (122, 4)\n",
            "Rep 28 shape for IMG_5731.mov.mp4: (129, 4)\n",
            "Loaded 29 reps from IMG_5731.mov.mp4\n",
            "Rep 0 shape for IMG_5730.mov.mp4: (112, 4)\n",
            "Rep 1 shape for IMG_5730.mov.mp4: (124, 4)\n",
            "Rep 2 shape for IMG_5730.mov.mp4: (131, 4)\n",
            "Rep 3 shape for IMG_5730.mov.mp4: (182, 4)\n",
            "Rep 4 shape for IMG_5730.mov.mp4: (283, 4)\n",
            "Loaded 5 reps from IMG_5730.mov.mp4\n",
            "Rep 0 shape for IMG_5733.mov.mp4: (75, 4)\n",
            "Rep 1 shape for IMG_5733.mov.mp4: (69, 4)\n",
            "Rep 2 shape for IMG_5733.mov.mp4: (66, 4)\n",
            "Rep 3 shape for IMG_5733.mov.mp4: (65, 4)\n",
            "Rep 4 shape for IMG_5733.mov.mp4: (72, 4)\n",
            "Rep 5 shape for IMG_5733.mov.mp4: (62, 4)\n",
            "Rep 6 shape for IMG_5733.mov.mp4: (67, 4)\n",
            "Rep 7 shape for IMG_5733.mov.mp4: (67, 4)\n",
            "Rep 8 shape for IMG_5733.mov.mp4: (69, 4)\n",
            "Rep 9 shape for IMG_5733.mov.mp4: (71, 4)\n",
            "Rep 10 shape for IMG_5733.mov.mp4: (70, 4)\n",
            "Rep 11 shape for IMG_5733.mov.mp4: (70, 4)\n",
            "Rep 12 shape for IMG_5733.mov.mp4: (70, 4)\n",
            "Rep 13 shape for IMG_5733.mov.mp4: (69, 4)\n",
            "Rep 14 shape for IMG_5733.mov.mp4: (76, 4)\n",
            "Rep 15 shape for IMG_5733.mov.mp4: (79, 4)\n",
            "Rep 16 shape for IMG_5733.mov.mp4: (78, 4)\n",
            "Rep 17 shape for IMG_5733.mov.mp4: (77, 4)\n",
            "Rep 18 shape for IMG_5733.mov.mp4: (79, 4)\n",
            "Rep 19 shape for IMG_5733.mov.mp4: (91, 4)\n",
            "Rep 20 shape for IMG_5733.mov.mp4: (101, 4)\n",
            "Rep 21 shape for IMG_5733.mov.mp4: (98, 4)\n",
            "Loaded 22 reps from IMG_5733.mov.mp4\n",
            "Rep 0 shape for IMG_5734.mov.mp4: (74, 4)\n",
            "Rep 1 shape for IMG_5734.mov.mp4: (75, 4)\n",
            "Rep 2 shape for IMG_5734.mov.mp4: (139, 4)\n",
            "Rep 3 shape for IMG_5734.mov.mp4: (148, 4)\n",
            "Rep 4 shape for IMG_5734.mov.mp4: (74, 4)\n",
            "Rep 5 shape for IMG_5734.mov.mp4: (430, 4)\n",
            "Rep 6 shape for IMG_5734.mov.mp4: (78, 4)\n",
            "Rep 7 shape for IMG_5734.mov.mp4: (156, 4)\n",
            "Rep 8 shape for IMG_5734.mov.mp4: (88, 4)\n",
            "Rep 9 shape for IMG_5734.mov.mp4: (105, 4)\n",
            "Rep 10 shape for IMG_5734.mov.mp4: (105, 4)\n",
            "Rep 11 shape for IMG_5734.mov.mp4: (127, 4)\n",
            "Rep 12 shape for IMG_5734.mov.mp4: (158, 4)\n",
            "Rep 13 shape for IMG_5734.mov.mp4: (167, 4)\n",
            "Loaded 14 reps from IMG_5734.mov.mp4\n",
            "Rep 0 shape for IMG_5737.mov.mp4: (72, 4)\n",
            "Rep 1 shape for IMG_5737.mov.mp4: (74, 4)\n",
            "Rep 2 shape for IMG_5737.mov.mp4: (119, 4)\n",
            "Rep 3 shape for IMG_5737.mov.mp4: (369, 4)\n",
            "Loaded 4 reps from IMG_5737.mov.mp4\n",
            "Rep 0 shape for IMG_5735.mov.mp4: (267, 4)\n",
            "Rep 1 shape for IMG_5735.mov.mp4: (280, 4)\n",
            "Rep 2 shape for IMG_5735.mov.mp4: (84, 4)\n",
            "Rep 3 shape for IMG_5735.mov.mp4: (84, 4)\n",
            "Rep 4 shape for IMG_5735.mov.mp4: (89, 4)\n",
            "Rep 5 shape for IMG_5735.mov.mp4: (91, 4)\n",
            "Rep 6 shape for IMG_5735.mov.mp4: (94, 4)\n",
            "Rep 7 shape for IMG_5735.mov.mp4: (103, 4)\n",
            "Rep 8 shape for IMG_5735.mov.mp4: (121, 4)\n",
            "Loaded 9 reps from IMG_5735.mov.mp4\n",
            "Rep 0 shape for IMG_5736.mov.mp4: (75, 4)\n",
            "Rep 1 shape for IMG_5736.mov.mp4: (62, 4)\n",
            "Rep 2 shape for IMG_5736.mov.mp4: (59, 4)\n",
            "Rep 3 shape for IMG_5736.mov.mp4: (57, 4)\n",
            "Rep 4 shape for IMG_5736.mov.mp4: (54, 4)\n",
            "Rep 5 shape for IMG_5736.mov.mp4: (53, 4)\n",
            "Rep 6 shape for IMG_5736.mov.mp4: (53, 4)\n",
            "Rep 7 shape for IMG_5736.mov.mp4: (53, 4)\n",
            "Rep 8 shape for IMG_5736.mov.mp4: (54, 4)\n",
            "Rep 9 shape for IMG_5736.mov.mp4: (54, 4)\n",
            "Rep 10 shape for IMG_5736.mov.mp4: (54, 4)\n",
            "Rep 11 shape for IMG_5736.mov.mp4: (56, 4)\n",
            "Rep 12 shape for IMG_5736.mov.mp4: (59, 4)\n",
            "Rep 13 shape for IMG_5736.mov.mp4: (68, 4)\n",
            "Rep 14 shape for IMG_5736.mov.mp4: (67, 4)\n",
            "Rep 15 shape for IMG_5736.mov.mp4: (71, 4)\n",
            "Rep 16 shape for IMG_5736.mov.mp4: (82, 4)\n",
            "Rep 17 shape for IMG_5736.mov.mp4: (84, 4)\n",
            "Rep 18 shape for IMG_5736.mov.mp4: (108, 4)\n",
            "Rep 19 shape for IMG_5736.mov.mp4: (111, 4)\n",
            "Rep 20 shape for IMG_5736.mov.mp4: (133, 4)\n",
            "Rep 21 shape for IMG_5736.mov.mp4: (149, 4)\n",
            "Rep 22 shape for IMG_5736.mov.mp4: (174, 4)\n",
            "Rep 23 shape for IMG_5736.mov.mp4: (220, 4)\n",
            "Loaded 24 reps from IMG_5736.mov.mp4\n",
            "Rep 0 shape for IMG_5738.mov.mp4: (115, 4)\n",
            "Rep 1 shape for IMG_5738.mov.mp4: (62, 4)\n",
            "Rep 2 shape for IMG_5738.mov.mp4: (63, 4)\n",
            "Rep 3 shape for IMG_5738.mov.mp4: (68, 4)\n",
            "Rep 4 shape for IMG_5738.mov.mp4: (68, 4)\n",
            "Rep 5 shape for IMG_5738.mov.mp4: (71, 4)\n",
            "Rep 6 shape for IMG_5738.mov.mp4: (73, 4)\n",
            "Rep 7 shape for IMG_5738.mov.mp4: (83, 4)\n",
            "Rep 8 shape for IMG_5738.mov.mp4: (104, 4)\n",
            "Rep 9 shape for IMG_5738.mov.mp4: (119, 4)\n",
            "Rep 10 shape for IMG_5738.mov.mp4: (145, 4)\n",
            "Rep 11 shape for IMG_5738.mov.mp4: (153, 4)\n",
            "Rep 12 shape for IMG_5738.mov.mp4: (269, 4)\n",
            "Loaded 13 reps from IMG_5738.mov.mp4\n",
            "Rep 0 shape for IMG_5741.mov.mp4: (179, 4)\n",
            "Rep 1 shape for IMG_5741.mov.mp4: (71, 4)\n",
            "Rep 2 shape for IMG_5741.mov.mp4: (77, 4)\n",
            "Rep 3 shape for IMG_5741.mov.mp4: (158, 4)\n",
            "Rep 4 shape for IMG_5741.mov.mp4: (161, 4)\n",
            "Rep 5 shape for IMG_5741.mov.mp4: (189, 4)\n",
            "Loaded 6 reps from IMG_5741.mov.mp4\n",
            "Rep 0 shape for IMG_5739.mov.mp4: (76, 4)\n",
            "Rep 1 shape for IMG_5739.mov.mp4: (97, 4)\n",
            "Rep 2 shape for IMG_5739.mov.mp4: (108, 4)\n",
            "Rep 3 shape for IMG_5739.mov.mp4: (148, 4)\n",
            "Rep 4 shape for IMG_5739.mov.mp4: (190, 4)\n",
            "Loaded 5 reps from IMG_5739.mov.mp4\n",
            "Rep 0 shape for IMG_5740.mov.mp4: (175, 4)\n",
            "Rep 1 shape for IMG_5740.mov.mp4: (181, 4)\n",
            "Rep 2 shape for IMG_5740.mov.mp4: (96, 4)\n",
            "Rep 3 shape for IMG_5740.mov.mp4: (96, 4)\n",
            "Rep 4 shape for IMG_5740.mov.mp4: (193, 4)\n",
            "Rep 5 shape for IMG_5740.mov.mp4: (393, 4)\n",
            "Loaded 6 reps from IMG_5740.mov.mp4\n",
            "Rep 0 shape for IMG_7770.mov.mp4: (72, 4)\n",
            "Rep 1 shape for IMG_7770.mov.mp4: (87, 4)\n",
            "Rep 2 shape for IMG_7770.mov.mp4: (105, 4)\n",
            "Rep 3 shape for IMG_7770.mov.mp4: (122, 4)\n",
            "Rep 4 shape for IMG_7770.mov.mp4: (109, 4)\n",
            "Rep 5 shape for IMG_7770.mov.mp4: (105, 4)\n",
            "Rep 6 shape for IMG_7770.mov.mp4: (119, 4)\n",
            "Rep 7 shape for IMG_7770.mov.mp4: (148, 4)\n",
            "Rep 8 shape for IMG_7770.mov.mp4: (130, 4)\n",
            "Rep 9 shape for IMG_7770.mov.mp4: (153, 4)\n",
            "Rep 10 shape for IMG_7770.mov.mp4: (149, 4)\n",
            "Rep 11 shape for IMG_7770.mov.mp4: (145, 4)\n",
            "Rep 12 shape for IMG_7770.mov.mp4: (216, 4)\n",
            "Rep 13 shape for IMG_7770.mov.mp4: (258, 4)\n",
            "Loaded 14 reps from IMG_7770.mov.mp4\n",
            "Rep 0 shape for IMG_7772.mov.mp4: (162, 4)\n",
            "Rep 1 shape for IMG_7772.mov.mp4: (244, 4)\n",
            "Rep 2 shape for IMG_7772.mov.mp4: (271, 4)\n",
            "Loaded 3 reps from IMG_7772.mov.mp4\n",
            "Rep 0 shape for IMG_7768.mov.mp4: (148, 4)\n",
            "Rep 1 shape for IMG_7768.mov.mp4: (162, 4)\n",
            "Rep 2 shape for IMG_7768.mov.mp4: (209, 4)\n",
            "Rep 3 shape for IMG_7768.mov.mp4: (325, 4)\n",
            "Rep 4 shape for IMG_7768.mov.mp4: (337, 4)\n",
            "Loaded 5 reps from IMG_7768.mov.mp4\n",
            "Rep 0 shape for IMG_7767.mov.mp4: (95, 4)\n",
            "Rep 1 shape for IMG_7767.mov.mp4: (87, 4)\n",
            "Rep 2 shape for IMG_7767.mov.mp4: (91, 4)\n",
            "Rep 3 shape for IMG_7767.mov.mp4: (103, 4)\n",
            "Rep 4 shape for IMG_7767.mov.mp4: (102, 4)\n",
            "Rep 5 shape for IMG_7767.mov.mp4: (118, 4)\n",
            "Rep 6 shape for IMG_7767.mov.mp4: (132, 4)\n",
            "Rep 7 shape for IMG_7767.mov.mp4: (132, 4)\n",
            "Rep 8 shape for IMG_7767.mov.mp4: (120, 4)\n",
            "Rep 9 shape for IMG_7767.mov.mp4: (127, 4)\n",
            "Rep 10 shape for IMG_7767.mov.mp4: (194, 4)\n",
            "Rep 11 shape for IMG_7767.mov.mp4: (308, 4)\n",
            "Rep 12 shape for IMG_7767.mov.mp4: (284, 4)\n",
            "Loaded 13 reps from IMG_7767.mov.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Prepare your data:\n",
        "all_sets_list = list(all_sets.values())\n"
      ],
      "metadata": {
        "id": "_Mgp9ff--WXC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "def augment_time_series(data, speed_range=(0.9, 1.1), noise_std=0.01):\n",
        "    \"\"\"\n",
        "    Augment a 7 x T time series by applying a random speed shift and jitter.\n",
        "\n",
        "    Parameters:\n",
        "        data (np.ndarray): Input array of shape (7, T)\n",
        "        speed_range (tuple): Range for random speed multiplier (e.g., 0.9 to 1.1)\n",
        "        noise_std (float): Standard deviation of Gaussian noise to add.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Augmented data of shape (7, T_augmented), where T_augmented is close to T.\n",
        "    \"\"\"\n",
        "    num_channels, T = data.shape\n",
        "\n",
        "    # 1. Time Warping (Speed Shifting)\n",
        "    # Choose a random speed factor within the specified range.\n",
        "    speed_factor = np.random.uniform(*speed_range)\n",
        "    # Create new time indices.\n",
        "    original_indices = np.arange(T)\n",
        "    new_length = int(T / speed_factor)\n",
        "    new_indices = np.linspace(0, T - 1, new_length)\n",
        "\n",
        "    # Interpolate each channel to the new time indices.\n",
        "    warped_data = np.zeros((num_channels, new_length))\n",
        "    for i in range(num_channels):\n",
        "        interp_func = interp1d(original_indices, data[i, :], kind='linear', fill_value=\"extrapolate\")\n",
        "        warped_data[i, :] = interp_func(new_indices)\n",
        "\n",
        "    # If you want the output to be the same length T, you can re-interpolate back to T timesteps.\n",
        "    re_indices = np.linspace(0, new_length - 1, T)\n",
        "    warped_data_fixed = np.zeros((num_channels, T))\n",
        "    for i in range(num_channels):\n",
        "        interp_func = interp1d(np.arange(new_length), warped_data[i, :], kind='linear', fill_value=\"extrapolate\")\n",
        "        warped_data_fixed[i, :] = interp_func(re_indices)\n",
        "\n",
        "    # 2. Jittering (Noise Injection)\n",
        "    noise = np.random.normal(0, noise_std, size=warped_data_fixed.shape)\n",
        "    augmented_data = warped_data_fixed + noise\n",
        "\n",
        "    return augmented_data"
      ],
      "metadata": {
        "id": "sGXtISYHR2rL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(all_sets.keys()))\n",
        "print(len(list(all_sets.keys())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seV3zBlPuw41",
        "outputId": "64d06548-b49d-47db-ebca-be5555074db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['t5.mp4', 't1.mp4', 't2.mp4', '5_l.mp4', '14r (1).mp4', '11r (1).mp4', '12r (1).mp4', '5_r.mp4', '10r (1).mp4', '8_r (1).mp4', 't4.mp4', '6_l.mp4', 't6.mp4', '9r (1).mp4', '7_r (1).mp4', 't3.mp4', '13r (1).mp4', '4_r.mp4', 'IMG_5788_cut.mp4', 'IMG_5797_bad_cut.mp4', 'IMG_5799_cut.mp4']\n",
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "processed_set = [prepare_rep_for_lstm_quantiles(rep, fps=30, num_quantiles=10) for rep in all_sets_list[20]]\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "rep_data = processed_set[8]  # Data for the first repetition\n",
        "feature_names = [\n",
        "    \"Normalized Elbow X\",\n",
        "    \"Normalized Elbow Y\",\n",
        "    \"Normalized Wrist X\",\n",
        "    \"Normalized Wrist Y\",\n",
        "    \"Elbow Velocity\",\n",
        "    \"Wrist Velocity\",\n",
        "    \"ROM Percentage\"\n",
        "]\n",
        "df = pd.DataFrame(rep_data, columns=feature_names)\n",
        "\n",
        "# Display the DataFrame as a table\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "zqANJ_7wVwom",
        "outputId": "63ecc8b3-0dce-46a3-f606-a19b57b7a675"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Normalized Elbow X  Normalized Elbow Y  Normalized Wrist X  \\\n",
              "0           50.573974          235.842781          115.373440   \n",
              "1           35.387049          222.185440          157.633080   \n",
              "2           74.181275          213.101959          266.738176   \n",
              "3           92.698066          200.378876          258.159635   \n",
              "4           83.202038          200.884933          124.844041   \n",
              "5           81.156178          191.943626           95.537410   \n",
              "6           84.866552          201.542130          227.540846   \n",
              "7           50.097141          208.479729          248.191924   \n",
              "8           29.373579          222.896309          147.039900   \n",
              "9           45.800800          236.748161           93.481936   \n",
              "\n",
              "   Normalized Wrist Y  Elbow Velocity  Wrist Velocity  ROM Percentage  \n",
              "0          446.028099       33.441170      102.248363        1.000000  \n",
              "1          372.692947       10.725019      464.420137        0.317312  \n",
              "2          195.994873       73.675040      343.704070        0.302030  \n",
              "3           70.972099       78.023698      566.128984        0.740776  \n",
              "4           18.441200       54.024022      509.398092        0.140075  \n",
              "5            8.946953       90.517726      345.964931        0.046387  \n",
              "6           71.156540       94.165807      625.687195        0.301050  \n",
              "7          214.532433      143.073323      468.403848        0.429713  \n",
              "8          377.602119       62.487263      359.794719        0.329641  \n",
              "9          431.483803       42.430549      103.955114        0.490012  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62da4c21-7d9c-4734-8661-c3766b7d115f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Normalized Elbow X</th>\n",
              "      <th>Normalized Elbow Y</th>\n",
              "      <th>Normalized Wrist X</th>\n",
              "      <th>Normalized Wrist Y</th>\n",
              "      <th>Elbow Velocity</th>\n",
              "      <th>Wrist Velocity</th>\n",
              "      <th>ROM Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50.573974</td>\n",
              "      <td>235.842781</td>\n",
              "      <td>115.373440</td>\n",
              "      <td>446.028099</td>\n",
              "      <td>33.441170</td>\n",
              "      <td>102.248363</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35.387049</td>\n",
              "      <td>222.185440</td>\n",
              "      <td>157.633080</td>\n",
              "      <td>372.692947</td>\n",
              "      <td>10.725019</td>\n",
              "      <td>464.420137</td>\n",
              "      <td>0.317312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>74.181275</td>\n",
              "      <td>213.101959</td>\n",
              "      <td>266.738176</td>\n",
              "      <td>195.994873</td>\n",
              "      <td>73.675040</td>\n",
              "      <td>343.704070</td>\n",
              "      <td>0.302030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>92.698066</td>\n",
              "      <td>200.378876</td>\n",
              "      <td>258.159635</td>\n",
              "      <td>70.972099</td>\n",
              "      <td>78.023698</td>\n",
              "      <td>566.128984</td>\n",
              "      <td>0.740776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>83.202038</td>\n",
              "      <td>200.884933</td>\n",
              "      <td>124.844041</td>\n",
              "      <td>18.441200</td>\n",
              "      <td>54.024022</td>\n",
              "      <td>509.398092</td>\n",
              "      <td>0.140075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>81.156178</td>\n",
              "      <td>191.943626</td>\n",
              "      <td>95.537410</td>\n",
              "      <td>8.946953</td>\n",
              "      <td>90.517726</td>\n",
              "      <td>345.964931</td>\n",
              "      <td>0.046387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>84.866552</td>\n",
              "      <td>201.542130</td>\n",
              "      <td>227.540846</td>\n",
              "      <td>71.156540</td>\n",
              "      <td>94.165807</td>\n",
              "      <td>625.687195</td>\n",
              "      <td>0.301050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>50.097141</td>\n",
              "      <td>208.479729</td>\n",
              "      <td>248.191924</td>\n",
              "      <td>214.532433</td>\n",
              "      <td>143.073323</td>\n",
              "      <td>468.403848</td>\n",
              "      <td>0.429713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>29.373579</td>\n",
              "      <td>222.896309</td>\n",
              "      <td>147.039900</td>\n",
              "      <td>377.602119</td>\n",
              "      <td>62.487263</td>\n",
              "      <td>359.794719</td>\n",
              "      <td>0.329641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>45.800800</td>\n",
              "      <td>236.748161</td>\n",
              "      <td>93.481936</td>\n",
              "      <td>431.483803</td>\n",
              "      <td>42.430549</td>\n",
              "      <td>103.955114</td>\n",
              "      <td>0.490012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62da4c21-7d9c-4734-8661-c3766b7d115f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62da4c21-7d9c-4734-8661-c3766b7d115f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62da4c21-7d9c-4734-8661-c3766b7d115f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7acd7970-fc4a-4ae7-b3f8-938396a4befa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7acd7970-fc4a-4ae7-b3f8-938396a4befa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7acd7970-fc4a-4ae7-b3f8-938396a4befa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2e6dcb3d-59ad-40e5-a4ae-7eef4925b66f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2e6dcb3d-59ad-40e5-a4ae-7eef4925b66f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Normalized Elbow X\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.93012470318929,\n        \"min\": 29.373579025268555,\n        \"max\": 92.69806623458862,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          29.373579025268555,\n          35.38704872131348,\n          81.15617752075195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Normalized Elbow Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.51930132586719,\n        \"min\": 191.9436264038086,\n        \"max\": 236.74816131591797,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          222.89630889892578,\n          222.18544006347656,\n          191.9436264038086\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Normalized Wrist X\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 69.55328742540235,\n        \"min\": 93.48193645477295,\n        \"max\": 266.7381763458252,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          147.0398998260498,\n          157.6330804824829,\n          95.53740978240967\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Normalized Wrist Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 174.51541492175465,\n        \"min\": 8.946952819824219,\n        \"max\": 446.0280990600586,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          377.6021194458008,\n          372.6929473876953,\n          8.946952819824219\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Elbow Velocity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.98945169332966,\n        \"min\": 10.725019487800456,\n        \"max\": 143.07332255677352,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          62.48726330127015,\n          10.725019487800456,\n          90.51772620897141\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Wrist Velocity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 177.0493152772405,\n        \"min\": 102.2483626287605,\n        \"max\": 625.6871949306064,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          359.79471928972634,\n          464.4201374961056,\n          345.9649309815353\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROM Percentage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2804663478364418,\n        \"min\": 0.04638698800220506,\n        \"max\": 1.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.3296409456408162,\n          0.3173122122317587,\n          0.04638698800220506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def random_rotation(data, max_angle=10):\n",
        "    \"\"\"Applies a random rotation to the joint coordinates.\"\"\"\n",
        "    angle = random.uniform(-max_angle, max_angle)\n",
        "    angle_rad = np.deg2rad(angle)\n",
        "    rotation_matrix = np.array([\n",
        "        [np.cos(angle_rad), -np.sin(angle_rad)],\n",
        "        [np.sin(angle_rad), np.cos(angle_rad)]\n",
        "    ])\n",
        "\n",
        "    # Assuming data has shape (timesteps, 4) [elbow_x, elbow_y, wrist_x, wrist_y]\n",
        "    rotated_data = data.copy()\n",
        "    for i in range(data.shape[0]):\n",
        "        elbow_coords = data[i, :2]\n",
        "        wrist_coords = data[i, 2:]\n",
        "\n",
        "        rotated_elbow = rotation_matrix @ elbow_coords\n",
        "        rotated_wrist = rotation_matrix @ wrist_coords\n",
        "\n",
        "        rotated_data[i, :2] = rotated_elbow\n",
        "        rotated_data[i, 2:] = rotated_wrist\n",
        "\n",
        "    return rotated_data"
      ],
      "metadata": {
        "id": "ZPtaLe_dLwci"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_scaling(data, scale_range=(0.9, 1.1)):\n",
        "    \"\"\"Applies a random scaling to the joint coordinates.\"\"\"\n",
        "    scale_factor = random.uniform(*scale_range)\n",
        "    scaled_data = data * scale_factor\n",
        "    return scaled_data"
      ],
      "metadata": {
        "id": "Facr7GQFLxFB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "def process_all_sets(all_sets, fps=30, num_quantiles=10, augment=True, num_augmentations=3):\n",
        "    processed_data = {}\n",
        "\n",
        "    for video_name, reps_list in all_sets.items():\n",
        "        # Original set key\n",
        "        processed_data[f\"{video_name}_set_0\"] = [\n",
        "            prepare_rep_for_lstm_quantiles(rep, fps, num_quantiles) for rep in reps_list\n",
        "        ]\n",
        "\n",
        "        # Generate and store augmented sets\n",
        "        if augment:\n",
        "            for aug_idx in range(1, num_augmentations + 1):\n",
        "                new_set = []\n",
        "                for rep in reps_list:\n",
        "                    # Apply augmentations\n",
        "                    aug_rep = augment_time_series(rep, speed_range=(0.95, 1.05), noise_std=0.02)\n",
        "                    aug_rep = random_rotation(aug_rep, max_angle=5)\n",
        "                    aug_rep = random_scaling(aug_rep, scale_range=(0.95, 1.05))\n",
        "\n",
        "                    # Process augmented rep with quantiles\n",
        "                    processed_rep = prepare_rep_for_lstm_quantiles(aug_rep, fps, num_quantiles)\n",
        "                    new_set.append(processed_rep)\n",
        "\n",
        "                # Save this set under a unique key\n",
        "                processed_data[f\"{video_name}_set_{aug_idx}\"] = new_set\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "\n",
        "\n",
        "# Assuming 'all_sets' is loaded as in your code\n",
        "processed_all_sets_data = process_all_sets(all_sets, augment=True)\n",
        "print(len(processed_all_sets_data))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjyVGXUQDMyo",
        "outputId": "005eefd6-217d-4460-89db-350e13bc7219"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage to display the processed data for the first video and first rep:\n",
        "\n",
        "first_video_name = list(processed_all_sets_data.keys())[7]\n",
        "first_rep_data = processed_all_sets_data[first_video_name][0]\n",
        "print(len(processed_all_sets_data[first_video_name]))\n",
        "print(first_video_name)\n",
        "feature_names = [\n",
        "    \"Normalized Elbow X\",\n",
        "    \"Normalized Elbow Y\",\n",
        "    \"Normalized Wrist X\",\n",
        "    \"Normalized Wrist Y\",\n",
        "    \"Elbow Velocity\",\n",
        "    \"Wrist Velocity\",\n",
        "    \"ROM Percentage\"\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(first_rep_data, columns=feature_names)\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "lDJC9QECaLJj",
        "outputId": "4313f6d1-0363-4670-d512-2f73606a2d41"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "t1.mp4_set_3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Normalized Elbow X  Normalized Elbow Y  Normalized Wrist X  \\\n",
              "0          -26.474505           73.000040          345.158142   \n",
              "1          -16.902059           50.272911          288.408338   \n",
              "2          -19.106716           -1.065736          148.480635   \n",
              "3          -37.191140           -5.341363           64.801274   \n",
              "4          -55.897564            1.918927           44.715492   \n",
              "5          -84.906741          -37.423701           46.003261   \n",
              "6          -62.514704          -32.287350          121.454665   \n",
              "7          -36.688156            8.877963          228.276533   \n",
              "8          -11.621169           60.010941          314.831484   \n",
              "9           -5.256744           85.404919          350.892599   \n",
              "\n",
              "   Normalized Wrist Y  Elbow Velocity  Wrist Velocity  ROM Percentage  \n",
              "0          617.610237       35.154987       92.549645        1.000000  \n",
              "1          546.003068      215.404908      839.774487        0.858479  \n",
              "2          341.870569       98.859498      771.775873        0.490532  \n",
              "3          143.466727       97.930855      479.222604        0.121157  \n",
              "4           66.365186      167.311141      101.968426        0.009361  \n",
              "5          149.469698       97.284046      305.427575        0.208826  \n",
              "6          328.810382       78.091387      732.887476        0.533777  \n",
              "7          494.698458      204.402943      589.226638        0.805581  \n",
              "8          587.470703       99.059491      200.033577        0.928404  \n",
              "9          613.390592       72.486075       57.239217        0.958803  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9930863e-df1e-4190-bb5f-e12c7d547c6f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Normalized Elbow X</th>\n",
              "      <th>Normalized Elbow Y</th>\n",
              "      <th>Normalized Wrist X</th>\n",
              "      <th>Normalized Wrist Y</th>\n",
              "      <th>Elbow Velocity</th>\n",
              "      <th>Wrist Velocity</th>\n",
              "      <th>ROM Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-26.474505</td>\n",
              "      <td>73.000040</td>\n",
              "      <td>345.158142</td>\n",
              "      <td>617.610237</td>\n",
              "      <td>35.154987</td>\n",
              "      <td>92.549645</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-16.902059</td>\n",
              "      <td>50.272911</td>\n",
              "      <td>288.408338</td>\n",
              "      <td>546.003068</td>\n",
              "      <td>215.404908</td>\n",
              "      <td>839.774487</td>\n",
              "      <td>0.858479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-19.106716</td>\n",
              "      <td>-1.065736</td>\n",
              "      <td>148.480635</td>\n",
              "      <td>341.870569</td>\n",
              "      <td>98.859498</td>\n",
              "      <td>771.775873</td>\n",
              "      <td>0.490532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-37.191140</td>\n",
              "      <td>-5.341363</td>\n",
              "      <td>64.801274</td>\n",
              "      <td>143.466727</td>\n",
              "      <td>97.930855</td>\n",
              "      <td>479.222604</td>\n",
              "      <td>0.121157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-55.897564</td>\n",
              "      <td>1.918927</td>\n",
              "      <td>44.715492</td>\n",
              "      <td>66.365186</td>\n",
              "      <td>167.311141</td>\n",
              "      <td>101.968426</td>\n",
              "      <td>0.009361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-84.906741</td>\n",
              "      <td>-37.423701</td>\n",
              "      <td>46.003261</td>\n",
              "      <td>149.469698</td>\n",
              "      <td>97.284046</td>\n",
              "      <td>305.427575</td>\n",
              "      <td>0.208826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-62.514704</td>\n",
              "      <td>-32.287350</td>\n",
              "      <td>121.454665</td>\n",
              "      <td>328.810382</td>\n",
              "      <td>78.091387</td>\n",
              "      <td>732.887476</td>\n",
              "      <td>0.533777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-36.688156</td>\n",
              "      <td>8.877963</td>\n",
              "      <td>228.276533</td>\n",
              "      <td>494.698458</td>\n",
              "      <td>204.402943</td>\n",
              "      <td>589.226638</td>\n",
              "      <td>0.805581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-11.621169</td>\n",
              "      <td>60.010941</td>\n",
              "      <td>314.831484</td>\n",
              "      <td>587.470703</td>\n",
              "      <td>99.059491</td>\n",
              "      <td>200.033577</td>\n",
              "      <td>0.928404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-5.256744</td>\n",
              "      <td>85.404919</td>\n",
              "      <td>350.892599</td>\n",
              "      <td>613.390592</td>\n",
              "      <td>72.486075</td>\n",
              "      <td>57.239217</td>\n",
              "      <td>0.958803</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9930863e-df1e-4190-bb5f-e12c7d547c6f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9930863e-df1e-4190-bb5f-e12c7d547c6f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9930863e-df1e-4190-bb5f-e12c7d547c6f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d1f37fca-8157-4655-a78a-09741bc351c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1f37fca-8157-4655-a78a-09741bc351c2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d1f37fca-8157-4655-a78a-09741bc351c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a142dcd8-d807-4b92-bfeb-46d9eb2fdfe3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a142dcd8-d807-4b92-bfeb-46d9eb2fdfe3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Normalized Elbow X\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.324220479749332,\n        \"min\": -84.90674148022494,\n        \"max\": -5.256744209168599,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -11.621168970795855,\n          -16.902058520378482,\n          -84.90674148022494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Normalized Elbow Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43.679414638458475,\n        \"min\": -37.42370101053544,\n        \"max\": 85.4049190781802,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          60.01094053986136,\n          50.27291117356916,\n          -37.42370101053544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Normalized Wrist X\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 124.87826240863397,\n        \"min\": 44.71549238204683,\n        \"max\": 350.8925990047498,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          314.8314844308046,\n          288.4083377255227,\n          46.003261100206096\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Normalized Wrist Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 212.2433100298413,\n        \"min\": 66.36518592004309,\n        \"max\": 617.610236527654,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          587.4707025145944,\n          546.0030676194233,\n          149.4696982605353\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Elbow Velocity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59.11351250559979,\n        \"min\": 35.154986699179084,\n        \"max\": 215.40490820392662,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          99.05949096058637,\n          215.40490820392662,\n          97.28404585363229\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Wrist Velocity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 303.93462962261617,\n        \"min\": 57.239216875559215,\n        \"max\": 839.7744871061703,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          200.03357683140067,\n          839.7744871061703,\n          305.4275750398956\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROM Percentage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.37304618529400274,\n        \"min\": 0.009360729119617306,\n        \"max\": 1.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.928404132715577,\n          0.858478804951939,\n          0.20882625498415985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'all_sets' is loaded and contains data for multiple videos\n",
        "first_video_name = list(all_sets.keys())[4]  # Get the name of the first video\n",
        "first_video_reps = all_sets[first_video_name] # Get all reps for the first video\n",
        "first_rep = first_video_reps[0]  # Get the first rep of the first video\n",
        "\n",
        "print(f\"Shape of the first rep in {first_video_name}: {first_rep.shape}\")\n",
        "print(f\"Data type of the first rep: {first_rep.dtype}\")\n",
        "print(f\"First few rows of the first rep:\\n{first_rep[:5]}\")  # Print first 5 rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwt97McCTlQp",
        "outputId": "ceba4c24-d95c-4144-de8d-5ce21db15a91"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the first rep in 14r (1).mp4: (148, 4)\n",
            "Data type of the first rep: float64\n",
            "First few rows of the first rep:\n",
            "[[ -1.47538662 192.78961182 -80.64505577 362.76763916]\n",
            " [  0.3851223  194.04258728 -81.63146496 363.66348267]\n",
            " [  2.98107147 194.92805481 -85.66550732 363.91998291]\n",
            " [  3.21573257 194.19487    -89.4613266  361.26594543]\n",
            " [  3.03291321 193.81858826 -94.99448776 359.11697388]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# def hinge_bce_loss(predictions, targets, margin=0.5, last_rep_weight=0.5):\n",
        "#     targets = targets.float()\n",
        "#     last_rep_idx = targets.shape[1] - 1  # Get last rep index\n",
        "\n",
        "#     probs = torch.sigmoid(predictions)  # Convert logits to probabilities\n",
        "\n",
        "#     # Hinge loss for early reps (should be below margin)\n",
        "#     early_reps_loss = torch.clamp(probs[:, :-1] - margin, min=0).mean()\n",
        "\n",
        "#     # BCE loss for the last rep (to encourage it to be higher but not crazy high)\n",
        "#     last_rep_loss = F.binary_cross_entropy(probs[:, last_rep_idx], targets[:, last_rep_idx])\n",
        "\n",
        "#     # Reduce the emphasis on last rep loss (smooth transition)\n",
        "#     total_loss = early_reps_loss + last_rep_weight * last_rep_loss\n",
        "#     return total_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "4HeTgbPrDMJy"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class DistanceWeightedBCELoss(nn.Module):\n",
        "#     def __init__(self, margin=0.5, weight=0.1, false_pos_penalty=2.0, miss_penalty=5.0):\n",
        "#         \"\"\"\n",
        "#         Distance-weighted loss that penalizes incorrect failure predictions\n",
        "#         based on their distance from the actual failure rep.\n",
        "\n",
        "#         Args:\n",
        "#         - margin: threshold for considering a prediction as failure.\n",
        "#         - weight: weight for distance penalty.\n",
        "#         - false_pos_penalty: penalty for predicting failure too early.\n",
        "#         - miss_penalty: penalty for missing the failure rep.\n",
        "#         \"\"\"\n",
        "#         super(DistanceWeightedBCELoss, self).__init__()\n",
        "#         self.margin = margin\n",
        "#         self.weight = weight\n",
        "#         self.false_pos_penalty = false_pos_penalty\n",
        "#         self.miss_penalty = miss_penalty\n",
        "#         self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#     def forward(self, logits, labels):\n",
        "#         probs = torch.sigmoid(logits)  # Convert logits to probabilities\n",
        "#         batch_size, seq_len = labels.shape\n",
        "\n",
        "#         #  Find actual failure rep (last \"1\" in labels)\n",
        "#         failure_indices = (labels == 1).nonzero(as_tuple=True)\n",
        "#         actual_fail_idx = failure_indices[1] if failure_indices[0].numel() > 0 else None\n",
        "\n",
        "#         #  Find first predicted failure rep (first rep > 0.5)\n",
        "#         predicted_fail_mask = (probs > self.margin).float()\n",
        "#         predicted_fail_indices = (predicted_fail_mask.cumsum(dim=1) == 1).float().argmax(dim=1)\n",
        "\n",
        "#         #  Compute distance penalty (only if failure exists)\n",
        "#         if actual_fail_idx is not None:\n",
        "#             distance = (predicted_fail_indices - actual_fail_idx).float().abs()\n",
        "#             penalty = (distance / seq_len).mean() * self.weight  # Normalize penalty\n",
        "#         else:\n",
        "#             penalty = torch.zeros(batch_size, device=logits.device)\n",
        "\n",
        "#         #  False positive penalty (if model predicts failure too early)\n",
        "#         false_positive_penalty = (predicted_fail_indices < actual_fail_idx).float().mean() * self.false_pos_penalty\n",
        "\n",
        "#         #  Miss penalty (if no failure is predicted at all)\n",
        "#         miss_penalty = (predicted_fail_mask.sum(dim=1) == 0).float().mean() * self.miss_penalty\n",
        "\n",
        "#         #  Compute BCE loss\n",
        "#         bce_loss = self.bce(logits, labels)\n",
        "\n",
        "#         #  Total loss (balanced penalties)\n",
        "#         total_loss = bce_loss + penalty + false_positive_penalty + miss_penalty\n",
        "\n",
        "#         return total_loss"
      ],
      "metadata": {
        "id": "v4J8t-HaPVVs"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class FirstFailDistanceLoss(nn.Module):\n",
        "#     def __init__(self, distance_weight=0.001, miss_penalty=0.9):\n",
        "#         \"\"\"\n",
        "#         distance_weight: How much we penalize failure predictions that are too early/late.\n",
        "#         miss_penalty: Extra penalty when the model completely fails to predict failure.\n",
        "#         \"\"\"\n",
        "#         super(FirstFailDistanceLoss, self).__init__()\n",
        "#         self.bce = nn.BCEWithLogitsLoss()\n",
        "#         self.distance_weight = distance_weight\n",
        "#         self.miss_penalty = miss_penalty  # Force model to always predict failure\n",
        "\n",
        "#     def forward(self, logits, labels):\n",
        "#         probs = torch.sigmoid(logits)\n",
        "#         batch_size, seq_len = labels.shape\n",
        "\n",
        "#         # Find actual failure rep (should be the last \"1\" in each sequence)\n",
        "#         failure_indices = (labels == 1).nonzero(as_tuple=True)\n",
        "#         actual_fail_idx = failure_indices[1] if failure_indices[0].numel() > 0 else None\n",
        "\n",
        "#         # Find first predicted failure rep\n",
        "#         predicted_fail_mask = (probs > 0.5).float()\n",
        "#         predicted_fail_indices = (predicted_fail_mask.cumsum(dim=1) == 1).float().argmax(dim=1)\n",
        "\n",
        "#         # Compute distance penalty\n",
        "#         if actual_fail_idx is not None:\n",
        "#             distance = (predicted_fail_indices - actual_fail_idx).float().abs()\n",
        "#             penalty = (distance / seq_len).mean()  # Linear penalty\n",
        "\n",
        "#             # **Force failure prediction:**\n",
        "#             miss_penalty = (predicted_fail_mask.sum(dim=1) == 0).float().mean() * self.miss_penalty  # If no failure is predicted, add penalty\n",
        "#         else:\n",
        "#             penalty = torch.zeros(batch_size, device=logits.device)\n",
        "#             miss_penalty = torch.zeros(batch_size, device=logits.device)  # No extra penalty if there's no actual failure (shouldn't happen)\n",
        "\n",
        "#         # BCE loss\n",
        "#         bce_loss = self.bce(logits, labels)\n",
        "\n",
        "#         # Push loss to encourage non-zero predictions\n",
        "#         push_loss = -0.005 * logits.mean()  # Small encouragement to push values up\n",
        "\n",
        "#         # Total loss\n",
        "#         total_loss = bce_loss + self.distance_weight * penalty + miss_penalty + push_loss\n",
        "#         return total_loss\n"
      ],
      "metadata": {
        "id": "Cyn02tr0QycU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# import numpy as np\n",
        "\n",
        "# # ---------------------------\n",
        "# # 1. Custom Dataset\n",
        "# # ---------------------------\n",
        "# class RepDataset(Dataset):\n",
        "#     \"\"\"\n",
        "#     Custom Dataset for handling reps stored in a dictionary.\n",
        "#     Each key corresponds to one set (e.g., one video), and the value is a list of 5x7 NumPy arrays.\n",
        "#     Each rep is flattened to a 70-dim vector.\n",
        "#     The labels are 0 for all reps except the last rep, which is labeled 1.\n",
        "#     \"\"\"\n",
        "#     def __init__(self, data_dict):\n",
        "#         self.data = []  # list of (sequence, labels)\n",
        "#         for key, reps in data_dict.items():\n",
        "#             # Flatten each 5x7 rep into a 70-dim vector.\n",
        "#             reps_flat = [rep.flatten() for rep in reps]\n",
        "#             # Create label: 0 for all except the last rep is 1.\n",
        "#             labels = [0] * (len(reps_flat) - 1) + [1]\n",
        "#             # Stack into an array with shape (seq_len, 35) and (seq_len,) for labels.\n",
        "#             sequence = np.stack(reps_flat)  # shape: (seq_len, 35)\n",
        "#             labels = np.array(labels)         # shape: (seq_len,)\n",
        "#             self.data.append((sequence, labels))\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         sequence, labels = self.data[idx]\n",
        "#         # Convert to torch tensors.\n",
        "#         sequence_tensor = torch.tensor(sequence, dtype=torch.float32)\n",
        "#         labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
        "#         return sequence_tensor, labels_tensor\n",
        "\n",
        "# # Example data dictionary (using your provided example snippet)\n",
        "# data = processed_all_sets_data\n",
        "\n",
        "\n",
        "# import random\n",
        "\n",
        "# # 1. Split the data\n",
        "# video_names = list(processed_all_sets_data.keys())\n",
        "# random.shuffle(video_names)  # Shuffle the video names\n",
        "# split_index = int(0.8 * len(video_names))  # 80% for training\n",
        "# train_video_names = video_names[:split_index]\n",
        "# val_video_names = video_names[split_index:]\n",
        "\n",
        "# # 2. Create training and validation data dictionaries\n",
        "# train_data = {key: processed_all_sets_data[key] for key in train_video_names}\n",
        "# val_data = {key: processed_all_sets_data[key] for key in val_video_names}\n",
        "\n",
        "# # 3. Create datasets and data loaders\n",
        "# train_dataset = RepDataset(train_data)\n",
        "# val_dataset = RepDataset(val_data)\n",
        "\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)  # No need to shuffle validation data\n",
        "\n",
        "# # ---------------------------\n",
        "# # 2. Model Implementation\n",
        "# # ---------------------------\n",
        "# class RepEncoder(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Encodes each rep (5x7 matrix flattened to a 35-dim vector) into a feature vector.\n",
        "#     \"\"\"\n",
        "#     def __init__(self, input_dim=70, embed_dim=64):\n",
        "#         super(RepEncoder, self).__init__()\n",
        "#         self.fc = nn.Linear(input_dim, embed_dim)\n",
        "#         self.relu = nn.ReLU()\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # x shape: (batch_size, seq_len, 35)\n",
        "#         out = self.fc(x)  # shape: (batch_size, seq_len, embed_dim)\n",
        "#         out = self.relu(out)\n",
        "#         return out\n",
        "\n",
        "# class LSTMClassifier(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Overall model:\n",
        "#       1. Each rep is optionally encoded via RepEncoder.\n",
        "#       2. An LSTM processes the sequence.\n",
        "#       3. At each timestep, the LSTM hidden state is passed to a classifier.\n",
        "#     \"\"\"\n",
        "#     def __init__(self, input_dim=70, embed_dim=64, lstm_hidden_dim=128, num_layers=1, use_encoder=False):\n",
        "#         super(LSTMClassifier, self).__init__()\n",
        "#         self.use_encoder = use_encoder\n",
        "#         if use_encoder:\n",
        "#             self.encoder = RepEncoder(input_dim=input_dim, embed_dim=embed_dim)\n",
        "#             lstm_input_dim = embed_dim\n",
        "#         else:\n",
        "#             lstm_input_dim = input_dim\n",
        "\n",
        "#         self.lstm = nn.LSTM(input_size=lstm_input_dim, hidden_size=lstm_hidden_dim,\n",
        "#                             num_layers=num_layers, batch_first=True)\n",
        "#         # Binary classifier: single output (logit) per timestep.\n",
        "#         self.classifier = nn.Linear(lstm_hidden_dim, 1)\n",
        "\n",
        "#     def forward(self, x, hidden=None):\n",
        "#         \"\"\"\n",
        "#         x: tensor of shape (batch_size, seq_len, input_dim) (input_dim=35)\n",
        "#         Returns:\n",
        "#             logits: tensor of shape (batch_size, seq_len)\n",
        "#         \"\"\"\n",
        "#         if self.use_encoder:\n",
        "#             x = self.encoder(x)  # shape becomes (batch_size, seq_len, embed_dim)\n",
        "\n",
        "#         lstm_out, hidden = self.lstm(x, hidden)  # lstm_out: (batch_size, seq_len, lstm_hidden_dim)\n",
        "#         logits = self.classifier(lstm_out)  # shape: (batch_size, seq_len, 1)\n",
        "#         return logits.squeeze(-1), hidden  # final shape: (batch_size, seq_len)\n",
        "\n",
        "# # ---------------------------\n",
        "# # 3. Training Setup\n",
        "# # ---------------------------\n",
        "# # Hyperparameters\n",
        "# learning_rate = 1e-3\n",
        "# lstm_hidden_dim = 32\n",
        "# embed_dim = 16\n",
        "\n",
        "# model = LSTMClassifier(input_dim=70, embed_dim=embed_dim, lstm_hidden_dim=lstm_hidden_dim, num_layers=1)\n",
        "# # Use BCEWithLogitsLoss (binary classification) with a positive class weight.\n",
        "# # Here pos_weight is tuned to give more weight to the failure (rare) class.\n",
        "# pos_weight = torch.tensor([10.0])\n",
        "\n",
        "# # criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "# # criterion = hinge_bce_loss\n",
        "# criterion = DistanceWeightedBCELoss()  # Adjust lambda as needed\n",
        "# # criterion = FirstFailDistanceLoss()\n",
        "\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "\n",
        "# # ---------------------------\n",
        "# # 4. Training Loop (Example)\n",
        "# # ---------------------------\n",
        "# model.train()\n",
        "# for epoch in range(50):\n",
        "#     epoch_loss = 0.0\n",
        "#     for sequences, labels in train_dataloader:\n",
        "#         # sequences shape: (batch_size, seq_len, 35)\n",
        "#         # labels shape: (batch_size, seq_len)\n",
        "#         optimizer.zero_grad()\n",
        "#         logits, _ = model(sequences)  # logits shape: (batch_size, seq_len)\n",
        "#         loss = criterion(logits, labels)\n",
        "#         epoch_loss += loss.item()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         # print(f\"Epoch {epoch+1} - Loss: {loss.item()}\")\n",
        "#     epoch_loss /= len(train_dataloader)\n",
        "#     model.eval()  # Set model to evaluation mode\n",
        "#     val_loss = 0.0\n",
        "#     with torch.no_grad():  # Disable gradient calculation during validation\n",
        "#         for sequences, labels in val_dataloader:\n",
        "#             logits, _ = model(sequences)\n",
        "#             loss = criterion(logits, labels)\n",
        "#             val_loss += loss.item()\n",
        "#     val_loss /= len(val_dataloader)\n",
        "#     print(f\"Epoch {epoch+1} - Average Training Loss: {epoch_loss}, Validation Loss: {val_loss}\")\n",
        "\n",
        "# # ---------------------------\n",
        "# # 5. Evaluation Example\n",
        "# # ---------------------------\n",
        "# # model.eval()\n",
        "# # with torch.no_grad():\n",
        "# #     for sequences, labels in val_dataloader:\n",
        "# #         logits, _ = model(sequences)\n",
        "# #         # Convert logits to probabilities\n",
        "# #         probabilities = torch.sigmoid(logits)\n",
        "# #         print(\"Predicted probabilities per rep:\")\n",
        "# #         print(probabilities)\n",
        "# #         print(\"Ground truth labels:\")\n",
        "# #         print(labels)\n"
      ],
      "metadata": {
        "id": "C17ePju3DDn_"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ---------------------------\n",
        "# # 5. Evaluation Example\n",
        "# # ---------------------------\n",
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#     for sequences, labels in val_dataloader:\n",
        "#         logits, _ = model(sequences)\n",
        "#         # Convert logits to probabilities\n",
        "#         probabilities = torch.sigmoid(logits)\n",
        "#         print(\"Predicted probabilities per rep:\")\n",
        "#         print(probabilities)\n",
        "#         print(\"Ground truth labels:\")\n",
        "#         print(labels)"
      ],
      "metadata": {
        "id": "oiI_flsU_EoH"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Suppose \"processed_all_sets_data\" has keys like:\n",
        "# t1.mp4_set_1, t1.mp4_set_2, t2.mp4_set_1, t2.mp4_set_2, etc.\n",
        "\n",
        "# 1) Group by the original video \"base name\"\n",
        "group_to_keys = defaultdict(list)\n",
        "\n",
        "for key in processed_all_sets_data.keys():\n",
        "    # Example key = \"t1.mp4_set_2\"\n",
        "    # Extract the base name before \"_set_\"\n",
        "    # If your naming is consistent, something like below should work:\n",
        "    base_name = key.split(\"_set_\")[0]  # \"t1.mp4\"\n",
        "\n",
        "    # Group them\n",
        "    group_to_keys[base_name].append(key)\n",
        "\n",
        "# 2) Create a list of the groups (i.e. the base videos)\n",
        "groups = list(group_to_keys.keys())\n",
        "random.shuffle(groups)\n",
        "\n",
        "# 3) Split on a group level, e.g. 80/20\n",
        "split_index = int(0.8 * len(groups))\n",
        "train_groups = groups[:split_index]\n",
        "val_groups   = groups[split_index:]\n",
        "\n",
        "# 4) For each group in train_groups, add all that group's keys to train_data\n",
        "train_data = {}\n",
        "val_data   = {}\n",
        "\n",
        "for g in train_groups:\n",
        "    for key in group_to_keys[g]:\n",
        "        train_data[key] = processed_all_sets_data[key]\n",
        "\n",
        "for g in val_groups:\n",
        "    for key in group_to_keys[g]:\n",
        "        val_data[key] = processed_all_sets_data[key]"
      ],
      "metadata": {
        "id": "XZBc3Epqt0zH"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SlidingWindowRepDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset that creates 3-rep sliding windows.\n",
        "    - Each sample consists of 3 consecutive reps.\n",
        "    - Label = 1 if the last rep in the window is a failure, otherwise 0.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_dict, balance_ratio=0.5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_dict: {key -> list_of_reps}, each list_of_reps is shape (R, 10, frame_dim)\n",
        "            balance_ratio: Percentage of failure cases (default 50%)\n",
        "        \"\"\"\n",
        "        self.samples = []\n",
        "        fail_samples = []\n",
        "        non_fail_samples = []\n",
        "\n",
        "        for key, list_of_reps in data_dict.items():\n",
        "            reps = np.stack(list_of_reps, axis=0)  # (R, 10, frame_dim)\n",
        "            R = reps.shape[0]\n",
        "\n",
        "            if R < 3:\n",
        "                continue  # Skip very short sequences\n",
        "\n",
        "            for i in range(R - 2):  # Sliding window of 3 reps\n",
        "                window = reps[i : i + 3]  # (3, 10, frame_dim)\n",
        "                fail = 1 if (i + 3 == R) else 0  # Fail if it's the last rep\n",
        "\n",
        "                if fail:\n",
        "                    fail_samples.append((window, fail))\n",
        "                else:\n",
        "                    non_fail_samples.append((window, fail))\n",
        "\n",
        "        # Balance 50/50 fail vs. non-fail\n",
        "        num_fail = len(fail_samples)\n",
        "        num_non_fail = int(num_fail / balance_ratio * (1 - balance_ratio))\n",
        "        non_fail_samples = random.sample(non_fail_samples, min(num_non_fail, len(non_fail_samples)))\n",
        "\n",
        "        self.samples = fail_samples + non_fail_samples\n",
        "        random.shuffle(self.samples)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        window, label = self.samples[idx]\n",
        "        return torch.tensor(window, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class LSTMFailurePredictor(nn.Module):\n",
        "    def __init__(self, frame_dim=7, rep_hidden_dim=32, lstm_hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(frame_dim, lstm_hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(lstm_hidden_dim, 1)  # Binary output\n",
        "\n",
        "    def forward(self, reps):\n",
        "        \"\"\"\n",
        "        reps: (batch_size, 3, 10, frame_dim)\n",
        "        \"\"\"\n",
        "        B, _, T, F = reps.shape\n",
        "        reps = reps.view(B * 3, T, F)  # Flatten 3-rep windows\n",
        "        lstm_out, _ = self.lstm(reps)  # LSTM over 10 frames per rep\n",
        "        lstm_out = lstm_out[:, -1, :]  # Take the last LSTM output for each rep\n",
        "        lstm_out = lstm_out.view(B, 3, -1)  # Reshape back to (B, 3, hidden_dim)\n",
        "        final_rep_encoding = lstm_out[:, -1, :]  # Take last rep's embedding\n",
        "        logits = self.fc(final_rep_encoding).squeeze(-1)  # Shape (B,)\n",
        "        return logits\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "train_dataset = SlidingWindowRepDataset(train_data, balance_ratio=0.5)\n",
        "val_dataset   = SlidingWindowRepDataset(val_data, balance_ratio=0.5)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Model, Loss, Optimizer\n",
        "model = LSTMFailurePredictor(frame_dim=7, rep_hidden_dim=32, lstm_hidden_dim=64)\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary classification loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 20\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    for reps, labels in train_dataloader:\n",
        "        logits = model(reps)\n",
        "        labels = labels.float()  # BCEWithLogitsLoss needs float labels\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {total_loss / len(train_dataloader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4atVrOYko2ke",
        "outputId": "2b27aefc-3c29-44b7-de74-e88994bc34b8"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 0.6892\n",
            "Epoch 2: Train Loss = 0.6600\n",
            "Epoch 3: Train Loss = 0.6396\n",
            "Epoch 4: Train Loss = 0.6144\n",
            "Epoch 5: Train Loss = 0.5999\n",
            "Epoch 6: Train Loss = 0.5909\n",
            "Epoch 7: Train Loss = 0.5638\n",
            "Epoch 8: Train Loss = 0.5469\n",
            "Epoch 9: Train Loss = 0.5322\n",
            "Epoch 10: Train Loss = 0.5264\n",
            "Epoch 11: Train Loss = 0.5020\n",
            "Epoch 12: Train Loss = 0.4900\n",
            "Epoch 13: Train Loss = 0.4761\n",
            "Epoch 14: Train Loss = 0.4655\n",
            "Epoch 15: Train Loss = 0.4566\n",
            "Epoch 16: Train Loss = 0.4433\n",
            "Epoch 17: Train Loss = 0.4245\n",
            "Epoch 18: Train Loss = 0.4159\n",
            "Epoch 19: Train Loss = 0.4095\n",
            "Epoch 20: Train Loss = 0.3958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "# Online Inference (Step by Step)\n",
        "model.eval()\n",
        "window = deque(maxlen=3)  # Store last 3 reps\n",
        "incoming_reps, fail_idx = next(val_iter)  # Get the first batch (shape: (1, R, 10, frame_dim))\n",
        "incoming_reps = incoming_reps.squeeze(0)\n",
        "\n",
        "print(\"total number of reps: \", len(incoming_reps))\n",
        "for t, rep in enumerate(incoming_reps):  # Assume `incoming_reps` is streaming reps\n",
        "    window.append(rep.numpy())  # Convert to numpy for deque storage\n",
        "\n",
        "    if len(window) == 3:  # Only start predicting after 3 reps\n",
        "        input_tensor = torch.tensor([list(window)], dtype=torch.float32)  # Shape (1,3,10,frame_dim)\n",
        "        logit = model(input_tensor)  # Single prediction\n",
        "        prob = torch.sigmoid(logit).item()  # Convert logit to probability\n",
        "\n",
        "        print(f\"Rep {t}: P(fail) = {prob:.4f}\")\n",
        "\n",
        "        if prob > 0.5:\n",
        "            print(f\" FAIL detected at rep {t}! Model stops.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePp81Dlbo8BH",
        "outputId": "eaec78b2-580a-4d08-d7b6-47473bff657d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of reps:  18\n",
            "Rep 2: P(fail) = 0.1720\n",
            "Rep 3: P(fail) = 0.1785\n",
            "Rep 4: P(fail) = 0.2570\n",
            "Rep 5: P(fail) = 0.1878\n",
            "Rep 6: P(fail) = 0.2266\n",
            "Rep 7: P(fail) = 0.2680\n",
            "Rep 8: P(fail) = 0.2267\n",
            "Rep 9: P(fail) = 0.2806\n",
            "Rep 10: P(fail) = 0.4237\n",
            "Rep 11: P(fail) = 0.2679\n",
            "Rep 12: P(fail) = 0.4143\n",
            "Rep 13: P(fail) = 0.3965\n",
            "Rep 14: P(fail) = 0.4103\n",
            "Rep 15: P(fail) = 0.4574\n",
            "Rep 16: P(fail) = 0.5260\n",
            " FAIL detected at rep 16! Model stops.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for reps, labels in val_dataloader:\n",
        "        logits = model(reps)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).long()  # Convert probabilities to 0/1 predictions\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "print(f\"Validation Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Validation Precision: {precision:.4f}\")\n",
        "print(f\"Validation Recall:    {recall:.4f}\")\n",
        "print(f\"Validation F1:        {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPZIEW71quh8",
        "outputId": "25433808-37f0-47ab-a14d-8ba4b69c684d"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.7292\n",
            "Validation Precision: 0.7750\n",
            "Validation Recall:    0.6458\n",
            "Validation F1:        0.7045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from collections import deque\n",
        "\n",
        "model.eval()\n",
        "\n",
        "distances = []\n",
        "with torch.no_grad():\n",
        "    for key, list_of_reps in val_data.items():\n",
        "        reps = np.stack(list_of_reps, axis=0)  # shape (R, 10, frame_dim)\n",
        "        R = reps.shape[0]\n",
        "\n",
        "        # If we have fewer than 3 reps, skip because our model needs 3 for the first prediction\n",
        "        if R < 3:\n",
        "            continue\n",
        "\n",
        "        window = deque(maxlen=3)\n",
        "        predicted_fail_idx = None  # Will store the index where model first says \"fail\"\n",
        "\n",
        "        for t in range(R):\n",
        "            rep = reps[t]\n",
        "            window.append(rep)\n",
        "\n",
        "            # Only start predicting once we have a full window of 3\n",
        "            if len(window) == 3:\n",
        "                input_tensor = torch.tensor([list(window)], dtype=torch.float32)  # shape (1,3,10,frame_dim)\n",
        "                logit = model(input_tensor)\n",
        "                prob = torch.sigmoid(logit).item()\n",
        "\n",
        "                if prob > 0.5:\n",
        "                    predicted_fail_idx = t\n",
        "                    break\n",
        "\n",
        "        # The *actual* fail is the last rep in this sequence\n",
        "        actual_fail_idx = R - 1\n",
        "\n",
        "        # Compute the difference (pred - actual). If no fail predicted, we can store None or a large penalty.\n",
        "        if predicted_fail_idx is not None:\n",
        "            dist = predicted_fail_idx - actual_fail_idx\n",
        "        else:\n",
        "            # E.g. if the model never predicted fail, treat as None or do something like dist=R\n",
        "            dist = None\n",
        "\n",
        "        distances.append(dist)\n",
        "\n",
        "# Filter out any None distances (for sequences with no fail prediction)\n",
        "valid_distances = [d for d in distances if d is not None]\n",
        "\n",
        "if len(valid_distances) > 0:\n",
        "    mean_distance = sum(valid_distances) / len(valid_distances)\n",
        "    print(f\"Mean Distance Between Predicted Fail and Actual Fail: {mean_distance:.4f}\")\n",
        "    print(\"(Negative => predicted earlier than actual fail\")\n",
        "else:\n",
        "    print(\"No fail was ever predicted on the validation set (all predicted_fail_idx were None).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hCI7ip1ro4k",
        "outputId": "2f69fb6b-4423-4174-df04-cf7773aa521a"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Distance Between Predicted Fail and Actual Fail: -6.0976\n",
            "(Negative => predicted earlier than actual fail\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}